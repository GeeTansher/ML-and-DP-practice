2022-09-26 23:10:42,694:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-09-26 23:10:42,699:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-09-26 23:10:42,699:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-09-26 23:10:42,699:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-09-26 23:10:48,372:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2022-09-26 23:28:51,389:INFO:PyCaret RegressionExperiment
2022-09-26 23:28:51,389:INFO:Logging name: reg-default-name
2022-09-26 23:28:51,389:INFO:ML Usecase: MLUsecase.REGRESSION
2022-09-26 23:28:51,389:INFO:version 3.0.0.rc4
2022-09-26 23:28:51,389:INFO:Initializing setup()
2022-09-26 23:28:51,389:INFO:self.USI: 2f58
2022-09-26 23:28:51,389:INFO:self.variable_keys: {'y_test', '_available_plots', 'gpu_param', 'fold_groups_param', 'data', 'memory', 'target_param', 'idx', 'seed', 'log_plots_param', 'fold_generator', 'transform_target_param', 'exp_id', 'pipeline', 'X_test', 'X', 'fold_shuffle_param', 'USI', 'y_train', 'variable_keys', 'logging_param', 'n_jobs_param', 'display_container', 'html_param', 'master_model_container', '_gpu_n_jobs_param', '_ml_usecase', '_all_models_internal', 'X_train', 'transform_target_method_param', 'y', '_all_models', 'exp_name_log', '_all_metrics'}
2022-09-26 23:28:51,390:INFO:Checking environment
2022-09-26 23:28:51,390:INFO:python_version: 3.9.7
2022-09-26 23:28:51,390:INFO:python_build: ('tags/v3.9.7:1016ef3', 'Aug 30 2021 20:19:38')
2022-09-26 23:28:51,390:INFO:machine: AMD64
2022-09-26 23:28:51,390:INFO:platform: Windows-10-10.0.22622-SP0
2022-09-26 23:28:51,391:INFO:Memory: svmem(total=8416038912, available=1044520960, percent=87.6, used=7371517952, free=1044520960)
2022-09-26 23:28:51,391:INFO:Physical Core: 4
2022-09-26 23:28:51,392:INFO:Logical Core: 8
2022-09-26 23:28:51,392:INFO:Checking libraries
2022-09-26 23:28:51,392:INFO:System:
2022-09-26 23:28:51,392:INFO:    python: 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]
2022-09-26 23:28:51,392:INFO:executable: c:\Users\HP\AppData\Local\Programs\Python\Python39\python.exe
2022-09-26 23:28:51,392:INFO:   machine: Windows-10-10.0.22622-SP0
2022-09-26 23:28:51,392:INFO:PyCaret required dependencies:
2022-09-26 23:28:51,393:INFO:                 pip: 22.2.2
2022-09-26 23:28:51,393:INFO:          setuptools: 57.4.0
2022-09-26 23:28:51,393:INFO:             pycaret: 3.0.0rc4
2022-09-26 23:28:51,393:INFO:             IPython: 8.4.0
2022-09-26 23:28:51,394:INFO:          ipywidgets: 8.0.2
2022-09-26 23:28:51,394:INFO:                tqdm: 4.64.0
2022-09-26 23:28:51,394:INFO:               numpy: 1.22.4
2022-09-26 23:28:51,394:INFO:              pandas: 1.4.2
2022-09-26 23:28:51,395:INFO:              jinja2: 3.1.2
2022-09-26 23:28:51,395:INFO:               scipy: 1.8.1
2022-09-26 23:28:51,395:INFO:              joblib: 1.1.0
2022-09-26 23:28:51,395:INFO:             sklearn: 1.1.2
2022-09-26 23:28:51,395:INFO:                pyod: 1.0.5
2022-09-26 23:28:51,395:INFO:            imblearn: 0.9.1
2022-09-26 23:28:51,395:INFO:   category_encoders: 2.5.0
2022-09-26 23:28:51,395:INFO:            lightgbm: 3.3.2
2022-09-26 23:28:51,395:INFO:               numba: 0.55.2
2022-09-26 23:28:51,396:INFO:            requests: 2.28.1
2022-09-26 23:28:51,396:INFO:          matplotlib: 3.5.3
2022-09-26 23:28:51,396:INFO:          scikitplot: 0.3.7
2022-09-26 23:28:51,396:INFO:         yellowbrick: 1.5
2022-09-26 23:28:51,396:INFO:              plotly: 5.10.0
2022-09-26 23:28:51,397:INFO:             kaleido: 0.2.1
2022-09-26 23:28:51,397:INFO:         statsmodels: 0.13.2
2022-09-26 23:28:51,397:INFO:              sktime: 0.13.3
2022-09-26 23:28:51,397:INFO:               tbats: 1.1.0
2022-09-26 23:28:51,398:INFO:            pmdarima: 1.8.5
2022-09-26 23:28:51,398:INFO:              psutil: 5.9.1
2022-09-26 23:28:51,398:INFO:PyCaret optional dependencies:
2022-09-26 23:28:51,472:INFO:                shap: Not installed
2022-09-26 23:28:51,472:INFO:           interpret: Not installed
2022-09-26 23:28:51,472:INFO:                umap: Not installed
2022-09-26 23:28:51,473:INFO:    pandas_profiling: Not installed
2022-09-26 23:28:51,474:INFO:  explainerdashboard: Not installed
2022-09-26 23:28:51,474:INFO:             autoviz: Not installed
2022-09-26 23:28:51,474:INFO:           fairlearn: Not installed
2022-09-26 23:28:51,474:INFO:             xgboost: Not installed
2022-09-26 23:28:51,475:INFO:            catboost: Not installed
2022-09-26 23:28:51,475:INFO:              kmodes: Not installed
2022-09-26 23:28:51,475:INFO:             mlxtend: Not installed
2022-09-26 23:28:51,475:INFO:       statsforecast: Not installed
2022-09-26 23:28:51,475:INFO:        tune_sklearn: Not installed
2022-09-26 23:28:51,475:INFO:                 ray: Not installed
2022-09-26 23:28:51,475:INFO:            hyperopt: Not installed
2022-09-26 23:28:51,475:INFO:              optuna: Not installed
2022-09-26 23:28:51,475:INFO:               skopt: Not installed
2022-09-26 23:28:51,475:INFO:              mlflow: Not installed
2022-09-26 23:28:51,475:INFO:              gradio: Not installed
2022-09-26 23:28:51,475:INFO:             fastapi: Not installed
2022-09-26 23:28:51,475:INFO:             uvicorn: Not installed
2022-09-26 23:28:51,478:INFO:              m2cgen: Not installed
2022-09-26 23:28:51,478:INFO:           evidently: Not installed
2022-09-26 23:28:51,478:INFO:                nltk: Not installed
2022-09-26 23:28:51,478:INFO:            pyLDAvis: Not installed
2022-09-26 23:28:51,478:INFO:              gensim: Not installed
2022-09-26 23:28:51,478:INFO:               spacy: Not installed
2022-09-26 23:28:51,478:INFO:           wordcloud: Not installed
2022-09-26 23:28:51,479:INFO:            textblob: Not installed
2022-09-26 23:28:51,479:INFO:               fugue: Not installed
2022-09-26 23:28:51,479:INFO:           streamlit: Not installed
2022-09-26 23:28:51,479:INFO:             prophet: Not installed
2022-09-26 23:28:51,479:INFO:None
2022-09-26 23:28:51,480:INFO:Set up data.
2022-09-26 23:28:51,575:INFO:Set up train/test split.
2022-09-26 23:28:51,614:INFO:Set up index.
2022-09-26 23:28:51,617:INFO:Set up folding strategy.
2022-09-26 23:28:51,617:INFO:Assigning column types.
2022-09-26 23:28:51,630:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-09-26 23:28:51,631:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-09-26 23:28:51,641:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-26 23:28:51,648:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-26 23:28:51,779:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-26 23:28:51,899:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-26 23:28:51,900:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:28:52,018:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:28:52,018:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-09-26 23:28:52,026:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-26 23:28:52,036:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-26 23:28:52,197:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-26 23:28:52,327:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-26 23:28:52,328:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:28:52,329:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:28:52,329:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-09-26 23:28:52,341:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-26 23:28:52,351:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-26 23:28:52,576:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-26 23:28:52,712:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-26 23:28:52,715:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:28:52,717:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:28:52,732:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-26 23:28:52,748:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-26 23:28:52,933:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-26 23:28:53,056:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-26 23:28:53,060:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:28:53,060:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:28:53,060:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-09-26 23:28:53,079:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-26 23:28:53,339:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-26 23:28:53,498:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-26 23:28:53,500:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:28:53,501:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:28:53,520:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-26 23:28:53,707:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-26 23:28:53,855:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-26 23:28:53,855:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:28:53,857:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:28:53,857:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-09-26 23:28:54,053:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-26 23:28:54,243:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-26 23:28:54,246:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:28:54,246:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:28:54,503:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-26 23:28:54,701:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-26 23:28:54,701:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:28:54,702:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:28:54,703:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-09-26 23:28:54,926:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-26 23:28:55,015:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:28:55,016:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:28:55,302:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-26 23:28:55,568:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:28:55,570:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:28:55,570:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-09-26 23:28:55,839:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:28:55,839:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:28:56,085:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:28:56,085:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:28:56,092:INFO:Preparing preprocessing pipeline...
2022-09-26 23:28:56,094:INFO:Set up simple imputation.
2022-09-26 23:28:56,110:INFO:Set up encoding of ordinal features.
2022-09-26 23:28:56,113:INFO:Set up encoding of categorical features.
2022-09-26 23:28:56,113:INFO:Set up variance threshold.
2022-09-26 23:28:56,113:INFO:Set up feature normalization.
2022-09-26 23:28:58,662:INFO:Finished creating preprocessing pipeline.
2022-09-26 23:28:58,688:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Id', 'MSSubClass', 'LotFrontage',
                                             'LotArea', 'OverallQual',
                                             'OverallCond', 'YearBuilt',
                                             'YearRemodAdd', 'MasVnrArea',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '1stFlrSF', '2ndFlrSF',
                                             'LowQualFinSF', 'GrLivArea',
                                             'BsmtFullBat...
                                                                         'Neighborhood',
                                                                         'Condition1',
                                                                         'Condition2',
                                                                         'HouseStyle',
                                                                         'RoofStyle',
                                                                         'RoofMatl',
                                                                         'Foundation',
                                                                         'BsmtFinType1',
                                                                         'BsmtFinType2',
                                                                         'GarageType',
                                                                         'SaleCondition'],
                                                                   handle_missing='return_nan',
                                                                   random_state=123))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2022-09-26 23:28:58,688:INFO:Creating final display dataframe.
2022-09-26 23:29:08,603:INFO:Setup display_container:                  Description             Value
0                 Session id               123
1                     Target         SalePrice
2                Target type        Regression
3                 Data shape       (1460, 149)
4           Train data shape       (1021, 149)
5            Test data shape        (439, 149)
6            Ignore features                 6
7           Ordinal features                 2
8           Numeric features                37
9       Categorical features                37
10  Rows with missing values            100.0%
11                Preprocess              True
12           Imputation type            simple
13        Numeric imputation              mean
14    Categorical imputation          constant
15  Maximum one-hot encoding                 5
16           Encoding method              None
17    Low variance threshold                 0
18                 Normalize              True
19          Normalize method            zscore
20            Fold Generator             KFold
21               Fold Number                10
22                  CPU Jobs                -1
23                   Use GPU             False
24            Log Experiment             False
25           Experiment Name  reg-default-name
26                       USI              2f58
2022-09-26 23:29:09,046:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:29:09,046:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:29:09,346:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:29:09,346:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:29:09,378:INFO:setup() successfully completed in 18.03s...............
2022-09-26 23:30:28,800:INFO:Initializing compare_models()
2022-09-26 23:30:28,800:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDA934BC70>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002EDA934BC70>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-09-26 23:30:28,800:INFO:Checking exceptions
2022-09-26 23:30:28,812:INFO:Preparing display monitor
2022-09-26 23:30:28,946:INFO:Initializing Linear Regression
2022-09-26 23:30:28,953:INFO:Total runtime is 0.000125734011332194 minutes
2022-09-26 23:30:28,965:INFO:SubProcess create_model() called ==================================
2022-09-26 23:30:28,965:INFO:Initializing create_model()
2022-09-26 23:30:28,965:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDA934BC70>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ED934F5D30>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:30:28,965:INFO:Checking exceptions
2022-09-26 23:30:28,973:INFO:Importing libraries
2022-09-26 23:30:28,973:INFO:Copying training dataset
2022-09-26 23:30:28,992:INFO:Defining folds
2022-09-26 23:30:28,992:INFO:Declaring metric variables
2022-09-26 23:30:29,005:INFO:Importing untrained model
2022-09-26 23:30:29,022:INFO:Linear Regression Imported successfully
2022-09-26 23:30:29,048:INFO:Starting cross validation
2022-09-26 23:30:29,120:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:30:39,873:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:30:39,889:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:30:39,937:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:30:40,057:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:30:40,403:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:30:40,645:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:30:40,682:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:30:40,722:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:30:40,863:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:30:42,064:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:30:42,080:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:30:42,141:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:30:42,189:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:30:42,193:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:30:42,209:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:30:43,793:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:30:43,835:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:30:43,880:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:30:44,035:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:30:44,049:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:30:44,101:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:30:44,217:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:30:44,419:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:30:45,444:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:30:47,709:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:30:48,075:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:30:48,086:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:30:48,263:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:30:48,539:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:30:48,568:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:30:48,806:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:30:49,055:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:30:49,336:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:30:49,412:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:30:49,565:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:30:49,824:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:30:49,875:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:30:50,048:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:30:50,298:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:30:50,314:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:30:50,445:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:30:50,467:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:30:50,645:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:30:50,784:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:30:52,971:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:30:54,812:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:30:59,756:INFO:Calculating mean and std
2022-09-26 23:30:59,761:INFO:Creating metrics dataframe
2022-09-26 23:30:59,777:INFO:Uploading results into container
2022-09-26 23:30:59,777:INFO:Uploading model into container now
2022-09-26 23:30:59,781:INFO:master_model_container: 1
2022-09-26 23:30:59,781:INFO:display_container: 2
2022-09-26 23:30:59,781:INFO:LinearRegression(n_jobs=-1)
2022-09-26 23:30:59,785:INFO:create_model() successfully completed......................................
2022-09-26 23:31:00,112:INFO:SubProcess create_model() end ==================================
2022-09-26 23:31:00,112:INFO:Creating metrics dataframe
2022-09-26 23:31:00,142:INFO:Initializing Lasso Regression
2022-09-26 23:31:00,142:INFO:Total runtime is 0.5199451684951782 minutes
2022-09-26 23:31:00,156:INFO:SubProcess create_model() called ==================================
2022-09-26 23:31:00,157:INFO:Initializing create_model()
2022-09-26 23:31:00,157:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDA934BC70>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ED934F5D30>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:31:00,157:INFO:Checking exceptions
2022-09-26 23:31:00,165:INFO:Importing libraries
2022-09-26 23:31:00,165:INFO:Copying training dataset
2022-09-26 23:31:00,188:INFO:Defining folds
2022-09-26 23:31:00,188:INFO:Declaring metric variables
2022-09-26 23:31:00,196:INFO:Importing untrained model
2022-09-26 23:31:00,213:INFO:Lasso Regression Imported successfully
2022-09-26 23:31:00,236:INFO:Starting cross validation
2022-09-26 23:31:00,246:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:31:02,337:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.912e+10, tolerance: 5.687e+08
  model = cd_fast.enet_coordinate_descent(

2022-09-26 23:31:02,345:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.146e+10, tolerance: 6.209e+08
  model = cd_fast.enet_coordinate_descent(

2022-09-26 23:31:02,361:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.793e+09, tolerance: 5.835e+08
  model = cd_fast.enet_coordinate_descent(

2022-09-26 23:31:02,417:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.462e+10, tolerance: 6.209e+08
  model = cd_fast.enet_coordinate_descent(

2022-09-26 23:31:02,433:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.032e+10, tolerance: 6.033e+08
  model = cd_fast.enet_coordinate_descent(

2022-09-26 23:31:02,449:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+10, tolerance: 5.954e+08
  model = cd_fast.enet_coordinate_descent(

2022-09-26 23:31:02,481:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.313e+10, tolerance: 6.157e+08
  model = cd_fast.enet_coordinate_descent(

2022-09-26 23:31:02,585:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.514e+10, tolerance: 5.994e+08
  model = cd_fast.enet_coordinate_descent(

2022-09-26 23:31:04,260:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:31:04,367:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:31:04,405:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:31:04,408:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:31:05,497:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.301e+09, tolerance: 6.007e+08
  model = cd_fast.enet_coordinate_descent(

2022-09-26 23:31:05,569:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.507e+10, tolerance: 6.126e+08
  model = cd_fast.enet_coordinate_descent(

2022-09-26 23:31:07,114:INFO:Calculating mean and std
2022-09-26 23:31:07,114:INFO:Creating metrics dataframe
2022-09-26 23:31:07,129:INFO:Uploading results into container
2022-09-26 23:31:07,137:INFO:Uploading model into container now
2022-09-26 23:31:07,137:INFO:master_model_container: 2
2022-09-26 23:31:07,137:INFO:display_container: 2
2022-09-26 23:31:07,137:INFO:Lasso(random_state=123)
2022-09-26 23:31:07,137:INFO:create_model() successfully completed......................................
2022-09-26 23:31:07,355:INFO:SubProcess create_model() end ==================================
2022-09-26 23:31:07,371:INFO:Creating metrics dataframe
2022-09-26 23:31:07,389:INFO:Initializing Ridge Regression
2022-09-26 23:31:07,389:INFO:Total runtime is 0.6407154917716981 minutes
2022-09-26 23:31:07,389:INFO:SubProcess create_model() called ==================================
2022-09-26 23:31:07,389:INFO:Initializing create_model()
2022-09-26 23:31:07,389:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDA934BC70>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ED934F5D30>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:31:07,389:INFO:Checking exceptions
2022-09-26 23:31:07,402:INFO:Importing libraries
2022-09-26 23:31:07,402:INFO:Copying training dataset
2022-09-26 23:31:07,418:INFO:Defining folds
2022-09-26 23:31:07,418:INFO:Declaring metric variables
2022-09-26 23:31:07,435:INFO:Importing untrained model
2022-09-26 23:31:07,436:INFO:Ridge Regression Imported successfully
2022-09-26 23:31:07,450:INFO:Starting cross validation
2022-09-26 23:31:07,465:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:31:10,422:INFO:Calculating mean and std
2022-09-26 23:31:10,425:INFO:Creating metrics dataframe
2022-09-26 23:31:10,431:INFO:Uploading results into container
2022-09-26 23:31:10,431:INFO:Uploading model into container now
2022-09-26 23:31:10,439:INFO:master_model_container: 3
2022-09-26 23:31:10,439:INFO:display_container: 2
2022-09-26 23:31:10,439:INFO:Ridge(random_state=123)
2022-09-26 23:31:10,439:INFO:create_model() successfully completed......................................
2022-09-26 23:31:10,610:INFO:SubProcess create_model() end ==================================
2022-09-26 23:31:10,617:INFO:Creating metrics dataframe
2022-09-26 23:31:10,641:INFO:Initializing Elastic Net
2022-09-26 23:31:10,641:INFO:Total runtime is 0.6949213226636252 minutes
2022-09-26 23:31:10,657:INFO:SubProcess create_model() called ==================================
2022-09-26 23:31:10,661:INFO:Initializing create_model()
2022-09-26 23:31:10,661:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDA934BC70>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ED934F5D30>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:31:10,661:INFO:Checking exceptions
2022-09-26 23:31:10,669:INFO:Importing libraries
2022-09-26 23:31:10,669:INFO:Copying training dataset
2022-09-26 23:31:10,706:INFO:Defining folds
2022-09-26 23:31:10,706:INFO:Declaring metric variables
2022-09-26 23:31:10,722:INFO:Importing untrained model
2022-09-26 23:31:10,734:INFO:Elastic Net Imported successfully
2022-09-26 23:31:10,763:INFO:Starting cross validation
2022-09-26 23:31:10,779:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:31:13,628:INFO:Calculating mean and std
2022-09-26 23:31:13,630:INFO:Creating metrics dataframe
2022-09-26 23:31:13,637:INFO:Uploading results into container
2022-09-26 23:31:13,637:INFO:Uploading model into container now
2022-09-26 23:31:13,637:INFO:master_model_container: 4
2022-09-26 23:31:13,637:INFO:display_container: 2
2022-09-26 23:31:13,637:INFO:ElasticNet(random_state=123)
2022-09-26 23:31:13,637:INFO:create_model() successfully completed......................................
2022-09-26 23:31:13,806:INFO:SubProcess create_model() end ==================================
2022-09-26 23:31:13,809:INFO:Creating metrics dataframe
2022-09-26 23:31:13,826:INFO:Initializing Least Angle Regression
2022-09-26 23:31:13,826:INFO:Total runtime is 0.7480020244916281 minutes
2022-09-26 23:31:13,837:INFO:SubProcess create_model() called ==================================
2022-09-26 23:31:13,837:INFO:Initializing create_model()
2022-09-26 23:31:13,842:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDA934BC70>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ED934F5D30>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:31:13,842:INFO:Checking exceptions
2022-09-26 23:31:13,851:INFO:Importing libraries
2022-09-26 23:31:13,851:INFO:Copying training dataset
2022-09-26 23:31:13,860:INFO:Defining folds
2022-09-26 23:31:13,860:INFO:Declaring metric variables
2022-09-26 23:31:13,874:INFO:Importing untrained model
2022-09-26 23:31:13,886:INFO:Least Angle Regression Imported successfully
2022-09-26 23:31:13,890:INFO:Starting cross validation
2022-09-26 23:31:13,920:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:31:15,174:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:31:15,174:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:31:15,192:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:31:15,247:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:31:15,247:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=7.237e+01, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,247:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=4.623e+01, with an active set of 58 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,250:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=3.434e+01, with an active set of 71 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,250:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=4.368e+01, with an active set of 60 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,250:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=6.194e+01, with an active set of 50 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,250:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=3.192e+01, with an active set of 72 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,255:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=3.011e+01, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,255:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:31:15,255:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=5.871e+01, with an active set of 52 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,255:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=3.784e+01, with an active set of 66 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,255:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=2.813e+01, with an active set of 75 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,255:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=5.463e+01, with an active set of 56 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,255:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=2.595e+01, with an active set of 80 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,264:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=2.501e+01, with an active set of 81 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,264:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=2.429e+01, with an active set of 81 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,264:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=4.043e+01, with an active set of 73 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,264:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=5.312e+01, with an active set of 62 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,264:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=3.372e+01, with an active set of 75 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,264:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=2.422e+01, with an active set of 84 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,264:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=3.238e+01, with an active set of 75 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,264:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=4.710e+01, with an active set of 65 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,264:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=2.116e+01, with an active set of 87 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,272:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.103e+01, with an active set of 88 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,273:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=3.511e+01, with an active set of 79 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,273:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 82 iterations, i.e. alpha=4.296e+01, with an active set of 72 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,273:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.857e+01, with an active set of 93 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,273:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.856e+01, with an active set of 93 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,273:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=4.231e+01, with an active set of 73 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,273:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.844e+01, with an active set of 93 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,273:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=2.770e+01, with an active set of 83 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,273:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=2.642e+01, with an active set of 84 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,280:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=2.527e+01, with an active set of 86 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,280:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=4.360e+01, with an active set of 81 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,280:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.646e+01, with an active set of 98 regressors, and the smallest cholesky pivot element being 8.229e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,280:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=2.465e+01, with an active set of 90 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,280:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=1.531e+01, with an active set of 99 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,280:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=9.488e+01, with an active set of 37 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,280:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=1.474e+01, with an active set of 99 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,280:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 99 iterations, i.e. alpha=3.736e+01, with an active set of 83 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,280:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=2.422e+01, with an active set of 93 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,288:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=2.132e+01, with an active set of 94 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,288:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=1.468e+01, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,288:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=9.374e+01, with an active set of 42 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,288:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=1.315e+01, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,288:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=4.166e+01, with an active set of 62 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,288:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=8.169e+01, with an active set of 44 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,288:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=5.796e+01, with an active set of 89 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,288:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=1.766e+01, with an active set of 98 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,296:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=5.154e+01, with an active set of 93 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,297:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=6.928e+01, with an active set of 49 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,297:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=1.182e+01, with an active set of 107 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,297:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=6.216e+01, with an active set of 51 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,300:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=4.809e+01, with an active set of 97 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,300:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 119 iterations, i.e. alpha=1.590e+01, with an active set of 106 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,300:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=2.871e+01, with an active set of 74 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,300:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 140 iterations, i.e. alpha=1.155e+01, with an active set of 110 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,300:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.429e+01, with an active set of 108 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,300:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.345e+01, with an active set of 108 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,300:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 140 iterations, i.e. alpha=1.122e+01, with an active set of 110 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,300:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.342e+01, with an active set of 108 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,305:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=5.726e+01, with an active set of 58 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,305:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 140 iterations, i.e. alpha=9.169e+00, with an active set of 110 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,305:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=8.536e+00, with an active set of 112 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,305:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=4.618e+01, with an active set of 105 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,307:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 143 iterations, i.e. alpha=6.127e+00, with an active set of 113 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,308:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=5.097e+01, with an active set of 64 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,308:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 144 iterations, i.e. alpha=5.592e+00, with an active set of 114 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,308:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=5.070e+01, with an active set of 65 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,308:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 144 iterations, i.e. alpha=5.551e+00, with an active set of 114 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,308:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 144 iterations, i.e. alpha=5.515e+00, with an active set of 114 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,308:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=2.596e+01, with an active set of 83 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,308:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 133 iterations, i.e. alpha=4.392e+01, with an active set of 110 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,308:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 144 iterations, i.e. alpha=4.674e+00, with an active set of 114 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,308:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 144 iterations, i.e. alpha=4.630e+00, with an active set of 114 regressors, and the smallest cholesky pivot element being 8.363e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,308:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=4.571e+01, with an active set of 68 regressors, and the smallest cholesky pivot element being 9.483e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(


2022-09-26 23:31:15,308:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=4.446e+01, with an active set of 68 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,313:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 145 iterations, i.e. alpha=4.224e+00, with an active set of 115 regressors, and the smallest cholesky pivot element being 8.363e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,313:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=4.082e+01, with an active set of 69 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,313:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=1.653e+01, with an active set of 117 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,313:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=3.732e+00, with an active set of 116 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,313:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:31:15,313:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 147 iterations, i.e. alpha=3.378e+00, with an active set of 117 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,313:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 136 iterations, i.e. alpha=1.359e+01, with an active set of 118 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,313:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 147 iterations, i.e. alpha=3.257e+00, with an active set of 117 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,313:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 148 iterations, i.e. alpha=3.114e+00, with an active set of 118 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,313:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=4.024e+01, with an active set of 117 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,313:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=3.923e+01, with an active set of 74 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,313:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 148 iterations, i.e. alpha=3.058e+00, with an active set of 118 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,313:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 139 iterations, i.e. alpha=1.338e+01, with an active set of 120 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,313:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 148 iterations, i.e. alpha=2.806e+00, with an active set of 118 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,313:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=3.919e+01, with an active set of 117 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,313:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 82 iterations, i.e. alpha=3.711e+01, with an active set of 75 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,313:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 139 iterations, i.e. alpha=1.322e+01, with an active set of 120 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,313:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=3.747e+01, with an active set of 117 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,313:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 139 iterations, i.e. alpha=1.068e+01, with an active set of 120 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,313:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=3.659e+01, with an active set of 117 regressors, and the smallest cholesky pivot element being 8.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,321:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=3.690e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,321:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=3.471e+01, with an active set of 117 regressors, and the smallest cholesky pivot element being 8.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,322:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 150 iterations, i.e. alpha=2.224e+00, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,322:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=3.619e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 9.483e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,322:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=3.610e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(


2022-09-26 23:31:15,322:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 150 iterations, i.e. alpha=1.988e+00, with an active set of 120 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,322:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 141 iterations, i.e. alpha=9.169e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,322:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 150 iterations, i.e. alpha=1.955e+00, with an active set of 120 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,322:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 150 iterations, i.e. alpha=1.887e+00, with an active set of 120 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,322:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 150 iterations, i.e. alpha=1.756e+00, with an active set of 120 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,322:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=8.714e+00, with an active set of 122 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,325:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=3.808e+01, with an active set of 119 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,325:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=8.538e+00, with an active set of 122 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,325:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=3.071e+01, with an active set of 119 regressors, and the smallest cholesky pivot element being 8.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,325:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=8.295e+00, with an active set of 122 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,325:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.946e+01, with an active set of 119 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,325:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.570e+01, with an active set of 119 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,325:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 153 iterations, i.e. alpha=1.622e+00, with an active set of 122 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,327:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 143 iterations, i.e. alpha=6.453e+00, with an active set of 123 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,327:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.486e+01, with an active set of 119 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,327:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 143 iterations, i.e. alpha=6.135e+00, with an active set of 123 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,329:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=1.519e+00, with an active set of 124 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,329:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 145 iterations, i.e. alpha=6.136e+00, with an active set of 124 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,330:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=3.169e+01, with an active set of 87 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,330:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=1.498e+00, with an active set of 124 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,330:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 145 iterations, i.e. alpha=5.918e+00, with an active set of 124 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,330:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 149 iterations, i.e. alpha=2.194e+01, with an active set of 122 regressors, and the smallest cholesky pivot element being 8.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,330:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 145 iterations, i.e. alpha=5.618e+00, with an active set of 124 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,330:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=3.032e+01, with an active set of 88 regressors, and the smallest cholesky pivot element being 9.483e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,330:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.152e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,330:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 145 iterations, i.e. alpha=5.046e+00, with an active set of 124 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,330:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=2.998e+01, with an active set of 88 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,330:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.132e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,330:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=8.757e-01, with an active set of 125 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,330:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=1.983e+01, with an active set of 124 regressors, and the smallest cholesky pivot element being 8.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,330:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=4.607e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,330:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=7.892e-01, with an active set of 125 regressors, and the smallest cholesky pivot element being 9.884e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,330:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=1.752e+01, with an active set of 124 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,330:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=7.613e-01, with an active set of 125 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,330:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=3.740e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,335:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=3.496e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,335:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=1.578e+01, with an active set of 124 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,335:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 158 iterations, i.e. alpha=6.329e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,335:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=3.183e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,335:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=1.571e+01, with an active set of 124 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,335:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=3.074e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,335:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=1.438e+01, with an active set of 124 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,335:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=5.291e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,335:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=1.247e+01, with an active set of 124 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,335:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=2.502e+01, with an active set of 94 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,335:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=5.099e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,338:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=1.191e+01, with an active set of 124 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,338:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=5.006e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,338:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=1.029e+01, with an active set of 124 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,338:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=2.400e+01, with an active set of 95 regressors, and the smallest cholesky pivot element being 9.483e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,338:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=4.140e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,338:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=7.964e+00, with an active set of 124 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,338:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.973e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,338:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=7.598e+00, with an active set of 124 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,338:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 149 iterations, i.e. alpha=4.934e+00, with an active set of 126 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,338:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.292e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,338:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=5.751e+00, with an active set of 124 regressors, and the smallest cholesky pivot element being 8.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,338:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 149 iterations, i.e. alpha=3.735e+00, with an active set of 126 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,338:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.285e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,338:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 149 iterations, i.e. alpha=2.750e+00, with an active set of 126 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,338:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.204e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,338:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=3.333e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,338:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 149 iterations, i.e. alpha=2.549e+00, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,338:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=2.305e+01, with an active set of 99 regressors, and the smallest cholesky pivot element being 9.483e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,338:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=2.790e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,338:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 149 iterations, i.e. alpha=1.950e+00, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,338:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=3.286e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,338:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 149 iterations, i.e. alpha=1.444e+00, with an active set of 126 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,338:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=3.112e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,338:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 149 iterations, i.e. alpha=1.377e+00, with an active set of 126 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,338:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=2.086e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.884e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,338:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=2.971e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,338:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 149 iterations, i.e. alpha=1.278e+00, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,338:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=2.083e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,338:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 149 iterations, i.e. alpha=1.253e+00, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,338:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=2.352e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 8.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,338:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=2.010e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,338:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 149 iterations, i.e. alpha=1.076e+00, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,338:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=2.196e+01, with an active set of 102 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,338:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=1.794e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,346:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 149 iterations, i.e. alpha=1.061e+00, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,346:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=1.344e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,346:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 149 iterations, i.e. alpha=1.061e+00, with an active set of 126 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,346:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=1.198e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,347:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=9.401e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,347:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=2.163e+00, with an active set of 126 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,347:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 150 iterations, i.e. alpha=8.267e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,348:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=2.102e+01, with an active set of 104 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,348:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=8.176e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,348:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=1.762e+00, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,348:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=2.043e+01, with an active set of 104 regressors, and the smallest cholesky pivot element being 9.483e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,348:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=5.458e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,348:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=1.326e+00, with an active set of 126 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,348:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 150 iterations, i.e. alpha=8.063e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,348:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=3.872e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,348:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=1.071e+00, with an active set of 126 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,348:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 150 iterations, i.e. alpha=6.724e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,350:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=3.554e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,350:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=1.071e+00, with an active set of 126 regressors, and the smallest cholesky pivot element being 8.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,351:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 150 iterations, i.e. alpha=5.647e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,351:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=2.921e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,351:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=1.037e+00, with an active set of 126 regressors, and the smallest cholesky pivot element being 8.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,351:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=2.697e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,351:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=8.623e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,351:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=2.299e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,351:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=5.161e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,351:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=8.333e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,351:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=2.221e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,351:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=3.916e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,351:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=1.660e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,354:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=3.389e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,354:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 155 iterations, i.e. alpha=7.798e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,354:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=2.752e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,354:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=1.383e-03, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,354:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 155 iterations, i.e. alpha=7.228e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,354:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 119 iterations, i.e. alpha=7.843e+01, with an active set of 106 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,354:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=2.609e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,356:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 119 iterations, i.e. alpha=7.511e+01, with an active set of 106 regressors, and the smallest cholesky pivot element being 9.714e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,356:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=2.218e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.885e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,356:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=2.101e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,356:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 155 iterations, i.e. alpha=7.106e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,357:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=2.066e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,357:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 155 iterations, i.e. alpha=5.313e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,358:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=1.618e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,358:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=5.293e+01, with an active set of 108 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,359:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=1.258e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,360:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=1.014e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,360:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=8.897e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,360:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 155 iterations, i.e. alpha=3.933e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,360:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=8.426e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,361:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 155 iterations, i.e. alpha=3.310e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,361:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=6.966e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,361:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 155 iterations, i.e. alpha=3.018e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,362:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=6.019e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,362:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 155 iterations, i.e. alpha=2.958e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,362:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 155 iterations, i.e. alpha=2.618e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,362:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=2.472e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,363:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=2.463e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,364:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 155 iterations, i.e. alpha=2.144e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,364:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 155 iterations, i.e. alpha=2.117e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,364:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 155 iterations, i.e. alpha=2.059e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,365:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 155 iterations, i.e. alpha=1.819e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 8.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,365:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:31:15,365:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 155 iterations, i.e. alpha=1.278e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,367:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 155 iterations, i.e. alpha=6.210e-02, with an active set of 127 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,378:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=6.480e+06, with an active set of 118 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,380:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=2.623e+01, with an active set of 81 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,384:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 190 iterations, i.e. alpha=1.470e+04, with an active set of 146 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,384:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=8.810e+06, with an active set of 125 regressors, and the smallest cholesky pivot element being 9.884e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,384:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 190 iterations, i.e. alpha=1.128e+04, with an active set of 146 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,386:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.766e+02, with an active set of 24 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,389:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=1.561e+02, with an active set of 30 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(


2022-09-26 23:31:15,392:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 115 iterations, i.e. alpha=6.535e+01, with an active set of 88 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,393:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 115 iterations, i.e. alpha=6.413e+01, with an active set of 88 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,394:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.351e+02, with an active set of 37 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,395:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=5.727e+01, with an active set of 91 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,396:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.261e+02, with an active set of 41 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,397:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=5.468e+01, with an active set of 93 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,398:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.112e+02, with an active set of 44 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,401:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:31:15,402:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=4.957e+01, with an active set of 98 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,402:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=4.948e+01, with an active set of 98 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,403:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=9.539e+01, with an active set of 52 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,406:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 203 iterations, i.e. alpha=3.327e+10, with an active set of 146 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,406:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=8.886e+01, with an active set of 56 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,408:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=7.996e+01, with an active set of 58 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,411:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 137 iterations, i.e. alpha=1.846e+06, with an active set of 103 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,412:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 137 iterations, i.e. alpha=1.832e+06, with an active set of 103 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,415:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=7.128e+01, with an active set of 66 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,416:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=6.907e+01, with an active set of 66 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,416:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 141 iterations, i.e. alpha=1.731e+06, with an active set of 105 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,417:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=6.986e+01, with an active set of 67 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,420:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=6.294e+01, with an active set of 69 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,421:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=5.824e+01, with an active set of 71 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,421:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 149 iterations, i.e. alpha=3.788e+06, with an active set of 109 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,422:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 149 iterations, i.e. alpha=2.173e+06, with an active set of 109 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,423:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 149 iterations, i.e. alpha=1.631e+06, with an active set of 109 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,423:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 149 iterations, i.e. alpha=1.460e+06, with an active set of 109 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,425:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=5.690e+01, with an active set of 74 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,425:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 149 iterations, i.e. alpha=1.365e+06, with an active set of 109 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,427:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=1.309e+06, with an active set of 111 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,428:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=5.484e+01, with an active set of 77 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,429:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 153 iterations, i.e. alpha=1.299e+06, with an active set of 112 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,431:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 155 iterations, i.e. alpha=1.152e+06, with an active set of 114 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,433:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.249e+06, with an active set of 115 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,435:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=4.956e+01, with an active set of 83 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,436:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.371e+06, with an active set of 117 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,436:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.362e+06, with an active set of 117 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,439:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=4.422e+01, with an active set of 87 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,440:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.541e+06, with an active set of 119 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,440:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.503e+06, with an active set of 119 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,442:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=1.145e+06, with an active set of 120 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,442:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=1.083e+06, with an active set of 120 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,443:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=1.076e+06, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,444:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=9.895e+05, with an active set of 121 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,444:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=4.484e+01, with an active set of 92 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,445:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=9.615e+05, with an active set of 121 regressors, and the smallest cholesky pivot element being 9.884e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,445:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=3.800e+01, with an active set of 92 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,448:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.313e+05, with an active set of 123 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,449:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.431e+05, with an active set of 123 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,450:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.343e+05, with an active set of 123 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,450:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=3.494e+01, with an active set of 64 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,451:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 172 iterations, i.e. alpha=7.852e+05, with an active set of 124 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,452:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 172 iterations, i.e. alpha=7.501e+05, with an active set of 124 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,452:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=3.352e+01, with an active set of 98 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,453:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 172 iterations, i.e. alpha=7.064e+05, with an active set of 124 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,453:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=3.205e+01, with an active set of 98 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,453:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 172 iterations, i.e. alpha=6.076e+05, with an active set of 124 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,454:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 172 iterations, i.e. alpha=5.526e+05, with an active set of 124 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,454:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 172 iterations, i.e. alpha=5.524e+05, with an active set of 124 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,456:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.196e+05, with an active set of 126 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(
2022-09-26 23:31:15,456:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=3.096e+01, with an active set of 100 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,457:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.134e+05, with an active set of 126 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,458:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=2.531e+01, with an active set of 74 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,458:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=4.971e+05, with an active set of 127 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,458:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=4.862e+05, with an active set of 127 regressors, and the smallest cholesky pivot element being 9.884e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,459:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=4.059e+05, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,460:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=3.771e+05, with an active set of 127 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,460:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=3.311e+05, with an active set of 127 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,460:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=2.750e+01, with an active set of 102 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,460:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=2.325e+01, with an active set of 77 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,461:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=3.185e+05, with an active set of 127 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,462:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=2.689e+05, with an active set of 127 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,462:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 119 iterations, i.e. alpha=2.579e+01, with an active set of 103 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,463:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.282e+05, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,465:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=2.203e+05, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,465:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=2.361e+01, with an active set of 106 regressors, and the smallest cholesky pivot element being 7.671e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,465:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.784e+05, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,465:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=2.067e+01, with an active set of 83 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,466:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.619e+05, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,467:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.277e+05, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,467:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.200e+05, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,468:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=6.410e+04, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,468:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=5.212e+04, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,469:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=1.749e+01, with an active set of 87 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,469:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=5.112e+04, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,469:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=5.083e+04, with an active set of 129 regressors, and the smallest cholesky pivot element being 9.996e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,470:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=3.006e+04, with an active set of 129 regressors, and the smallest cholesky pivot element being 9.996e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,470:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=1.638e+01, with an active set of 88 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,470:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=2.848e+04, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,470:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=1.571e+01, with an active set of 88 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,471:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.371e+04, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,471:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.058e+04, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,471:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=1.535e+01, with an active set of 89 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,472:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.018e+04, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,472:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.011e+04, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,473:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=2.511e+01, with an active set of 113 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,473:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=4.308e+03, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,473:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=9.824e+02, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,474:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=4.510e+02, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,474:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=3.966e+02, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,476:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 136 iterations, i.e. alpha=2.151e+01, with an active set of 116 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,478:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 138 iterations, i.e. alpha=2.018e+01, with an active set of 118 regressors, and the smallest cholesky pivot element being 9.125e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,479:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=1.361e+01, with an active set of 98 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,479:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=1.344e+01, with an active set of 98 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,479:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 140 iterations, i.e. alpha=2.009e+01, with an active set of 119 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,480:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 140 iterations, i.e. alpha=1.808e+01, with an active set of 119 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,480:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 140 iterations, i.e. alpha=1.514e+01, with an active set of 119 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,481:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 140 iterations, i.e. alpha=1.432e+01, with an active set of 119 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,482:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 141 iterations, i.e. alpha=9.947e+00, with an active set of 120 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,482:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 141 iterations, i.e. alpha=8.487e+00, with an active set of 120 regressors, and the smallest cholesky pivot element being 9.125e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,483:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=1.215e+01, with an active set of 104 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,483:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=1.201e+01, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,486:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=7.112e+00, with an active set of 123 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,486:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=1.123e+01, with an active set of 106 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,487:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=1.106e+01, with an active set of 106 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,488:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 147 iterations, i.e. alpha=6.681e+00, with an active set of 124 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,489:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=1.025e+01, with an active set of 107 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,490:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=9.802e+00, with an active set of 107 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,490:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=9.274e+00, with an active set of 107 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,491:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 150 iterations, i.e. alpha=1.561e+01, with an active set of 125 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,491:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=8.718e+00, with an active set of 107 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,491:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 150 iterations, i.e. alpha=9.058e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 9.365e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,492:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 150 iterations, i.e. alpha=6.942e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,492:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 150 iterations, i.e. alpha=6.365e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,493:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 150 iterations, i.e. alpha=6.237e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,493:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 150 iterations, i.e. alpha=5.864e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,494:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=7.051e+00, with an active set of 108 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,494:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 150 iterations, i.e. alpha=5.775e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,494:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=7.048e+00, with an active set of 108 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,494:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 150 iterations, i.e. alpha=5.503e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,495:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 150 iterations, i.e. alpha=4.598e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,495:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=6.666e+00, with an active set of 109 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,496:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 150 iterations, i.e. alpha=4.134e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 8.363e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,496:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=6.444e+00, with an active set of 109 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,496:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=5.832e+00, with an active set of 109 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,497:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=5.444e+00, with an active set of 109 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,498:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 115 iterations, i.e. alpha=5.248e+00, with an active set of 110 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,499:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=3.650e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,500:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=2.205e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,500:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=2.182e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,500:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=4.335e+00, with an active set of 112 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,500:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=2.107e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 9.365e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,501:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=2.075e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 9.996e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,504:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.876e+00, with an active set of 131 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,504:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=5.470e+00, with an active set of 115 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,505:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=4.208e+00, with an active set of 115 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,506:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.923e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,506:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.736e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,507:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.647e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,507:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.642e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,508:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.551e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,508:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=3.592e+00, with an active set of 116 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,508:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=3.564e+00, with an active set of 116 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,509:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=3.410e+00, with an active set of 116 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,510:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=3.302e+00, with an active set of 117 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,511:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=2.856e+00, with an active set of 117 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,512:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=2.781e+00, with an active set of 118 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,513:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=2.694e+00, with an active set of 118 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,513:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=2.634e+00, with an active set of 118 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,514:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=2.328e+00, with an active set of 118 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,515:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=2.303e+00, with an active set of 118 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,516:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 127 iterations, i.e. alpha=2.113e+00, with an active set of 119 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,517:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 127 iterations, i.e. alpha=1.649e+00, with an active set of 119 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,518:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 127 iterations, i.e. alpha=1.491e+00, with an active set of 119 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,518:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 127 iterations, i.e. alpha=1.318e+00, with an active set of 119 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,518:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 127 iterations, i.e. alpha=1.183e+00, with an active set of 119 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,519:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 127 iterations, i.e. alpha=1.008e+00, with an active set of 119 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,520:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=9.155e-01, with an active set of 120 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,522:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=8.866e-01, with an active set of 120 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,526:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=1.027e+00, with an active set of 124 regressors, and the smallest cholesky pivot element being 9.996e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,531:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 191 iterations, i.e. alpha=6.502e+03, with an active set of 146 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,559:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=8.767e+02, with an active set of 140 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,563:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 184 iterations, i.e. alpha=1.965e+03, with an active set of 142 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,564:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 185 iterations, i.e. alpha=1.393e+03, with an active set of 143 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,565:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 186 iterations, i.e. alpha=6.327e+02, with an active set of 144 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:15,567:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 188 iterations, i.e. alpha=1.877e+09, with an active set of 145 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,576:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:31:16,589:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:31:16,622:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.212e+02, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,622:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=5.311e+01, with an active set of 60 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,622:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=4.611e+01, with an active set of 65 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,622:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=4.801e+01, with an active set of 68 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,622:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=4.799e+01, with an active set of 69 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,635:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=1.132e+02, with an active set of 51 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,635:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 82 iterations, i.e. alpha=5.086e+01, with an active set of 72 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,635:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=1.109e+02, with an active set of 59 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,635:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=5.417e+01, with an active set of 79 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,635:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=1.093e+02, with an active set of 63 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,646:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=5.143e+01, with an active set of 81 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,646:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=5.054e+01, with an active set of 84 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,646:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=1.036e+02, with an active set of 69 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,646:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 99 iterations, i.e. alpha=4.900e+01, with an active set of 86 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,651:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=4.475e+01, with an active set of 91 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,656:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=4.570e+01, with an active set of 93 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,656:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=1.031e+02, with an active set of 79 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,656:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 115 iterations, i.e. alpha=4.665e+01, with an active set of 97 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,656:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 115 iterations, i.e. alpha=4.566e+01, with an active set of 97 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,656:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=4.541e+01, with an active set of 98 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,656:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=8.419e+01, with an active set of 89 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,667:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=8.280e+01, with an active set of 91 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,667:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=8.253e+01, with an active set of 91 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,667:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=5.619e+01, with an active set of 101 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,667:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=5.291e+01, with an active set of 101 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,667:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=7.679e+01, with an active set of 92 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,667:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=4.368e+01, with an active set of 104 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,667:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=6.471e+01, with an active set of 97 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,667:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=6.443e+01, with an active set of 97 regressors, and the smallest cholesky pivot element being 9.657e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,675:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=4.114e+01, with an active set of 107 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,675:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=6.226e+01, with an active set of 98 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,675:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=3.898e+01, with an active set of 107 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,678:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=3.824e+01, with an active set of 108 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,678:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=3.734e+01, with an active set of 108 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,679:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=3.018e+01, with an active set of 108 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,684:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=2.950e+01, with an active set of 110 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,685:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=5.766e+01, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,687:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=5.680e+01, with an active set of 107 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,687:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=5.017e+01, with an active set of 112 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,687:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 147 iterations, i.e. alpha=4.116e+03, with an active set of 116 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,700:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 150 iterations, i.e. alpha=3.837e+03, with an active set of 118 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,722:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 186 iterations, i.e. alpha=5.785e+04, with an active set of 140 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,722:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 186 iterations, i.e. alpha=5.033e+04, with an active set of 140 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,722:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 186 iterations, i.e. alpha=5.001e+04, with an active set of 140 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,722:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 189 iterations, i.e. alpha=6.827e+04, with an active set of 142 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,722:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 189 iterations, i.e. alpha=4.402e+04, with an active set of 142 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,729:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 196 iterations, i.e. alpha=3.993e+04, with an active set of 146 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,735:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 196 iterations, i.e. alpha=3.869e+04, with an active set of 146 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,739:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 199 iterations, i.e. alpha=3.545e+08, with an active set of 145 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:16,740:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 200 iterations, i.e. alpha=2.797e+08, with an active set of 146 regressors, and the smallest cholesky pivot element being 9.365e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:17,150:INFO:Calculating mean and std
2022-09-26 23:31:17,150:INFO:Creating metrics dataframe
2022-09-26 23:31:17,170:INFO:Uploading results into container
2022-09-26 23:31:17,170:INFO:Uploading model into container now
2022-09-26 23:31:17,170:INFO:master_model_container: 5
2022-09-26 23:31:17,170:INFO:display_container: 2
2022-09-26 23:31:17,170:INFO:Lars(random_state=123)
2022-09-26 23:31:17,175:INFO:create_model() successfully completed......................................
2022-09-26 23:31:17,414:INFO:SubProcess create_model() end ==================================
2022-09-26 23:31:17,414:INFO:Creating metrics dataframe
2022-09-26 23:31:17,438:INFO:Initializing Lasso Least Angle Regression
2022-09-26 23:31:17,438:INFO:Total runtime is 0.8082040150960288 minutes
2022-09-26 23:31:17,446:INFO:SubProcess create_model() called ==================================
2022-09-26 23:31:17,446:INFO:Initializing create_model()
2022-09-26 23:31:17,446:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDA934BC70>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ED934F5D30>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:31:17,446:INFO:Checking exceptions
2022-09-26 23:31:17,454:INFO:Importing libraries
2022-09-26 23:31:17,454:INFO:Copying training dataset
2022-09-26 23:31:17,462:INFO:Defining folds
2022-09-26 23:31:17,470:INFO:Declaring metric variables
2022-09-26 23:31:17,478:INFO:Importing untrained model
2022-09-26 23:31:17,486:INFO:Lasso Least Angle Regression Imported successfully
2022-09-26 23:31:17,511:INFO:Starting cross validation
2022-09-26 23:31:17,527:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:31:18,675:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-26 23:31:18,714:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-26 23:31:18,730:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-26 23:31:18,747:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-26 23:31:18,801:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=2.271e+01, with an active set of 72 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,808:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=2.809e+01, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,812:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=2.413e+01, with an active set of 69 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,812:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=2.413e+01, with an active set of 69 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,819:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=7.983e+00, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,821:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=7.983e+00, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,821:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=1.135e+01, with an active set of 93 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,822:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=1.127e+01, with an active set of 93 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,822:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 115 iterations, i.e. alpha=7.228e+00, with an active set of 101 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,825:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=3.275e+01, with an active set of 60 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,825:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=9.205e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 8.363e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,833:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 113 iterations, alpha=7.802e+00, previous alpha=6.908e+00, with an active set of 102 regressors.
  warnings.warn(

2022-09-26 23:31:18,838:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=3.797e+00, with an active set of 114 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,839:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=3.394e+00, with an active set of 115 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,840:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=3.362e+00, with an active set of 115 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,840:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=2.619e+01, with an active set of 65 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,840:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=1.207e+01, with an active set of 92 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,842:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=1.169e+01, with an active set of 93 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,843:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=2.812e+00, with an active set of 118 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,847:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=1.897e+00, with an active set of 119 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,847:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=1.896e+00, with an active set of 119 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,848:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=1.877e+00, with an active set of 119 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,848:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=1.873e+00, with an active set of 119 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,849:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=1.801e+00, with an active set of 119 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,849:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=1.688e+00, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,850:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 136 iterations, i.e. alpha=1.355e+00, with an active set of 120 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,851:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 136 iterations, i.e. alpha=1.325e+00, with an active set of 120 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,851:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 136 iterations, i.e. alpha=1.296e+00, with an active set of 120 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,853:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 136 iterations, i.e. alpha=1.261e+00, with an active set of 120 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,853:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 136 iterations, i.e. alpha=1.186e+00, with an active set of 120 regressors, and the smallest cholesky pivot element being 8.878e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,853:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=7.364e+00, with an active set of 104 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,853:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 136 iterations, i.e. alpha=1.179e+00, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,854:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 136 iterations, i.e. alpha=1.125e+00, with an active set of 120 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,854:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 136 iterations, i.e. alpha=1.105e+00, with an active set of 120 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,856:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 137 iterations, alpha=2.131e+00, previous alpha=1.003e+00, with an active set of 120 regressors.
  warnings.warn(

2022-09-26 23:31:18,857:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=4.766e+00, with an active set of 108 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,858:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=1.690e+01, with an active set of 82 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,860:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=1.632e+01, with an active set of 84 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,862:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=1.502e+01, with an active set of 86 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,862:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=3.647e+00, with an active set of 113 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,864:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=1.414e+01, with an active set of 89 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,865:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 133 iterations, i.e. alpha=3.504e+00, with an active set of 113 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,865:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=1.323e+01, with an active set of 90 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,866:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 133 iterations, i.e. alpha=3.504e+00, with an active set of 113 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,867:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=3.415e+00, with an active set of 114 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,868:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=3.293e+00, with an active set of 114 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,871:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=1.109e+01, with an active set of 95 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,871:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 135 iterations, alpha=3.909e+00, previous alpha=3.277e+00, with an active set of 114 regressors.
  warnings.warn(

2022-09-26 23:31:18,872:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=1.104e+01, with an active set of 95 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:18,874:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 111 iterations, alpha=1.084e+01, previous alpha=1.062e+01, with an active set of 96 regressors.
  warnings.warn(

2022-09-26 23:31:19,005:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-26 23:31:19,035:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-26 23:31:19,045:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-26 23:31:19,055:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=2.889e+01, with an active set of 66 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:19,065:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=2.472e+01, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:19,066:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=2.472e+01, with an active set of 72 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:19,067:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 82 iterations, i.e. alpha=2.271e+01, with an active set of 74 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:19,072:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 87 iterations, alpha=2.086e+01, previous alpha=2.042e+01, with an active set of 78 regressors.
  warnings.warn(

2022-09-26 23:31:19,091:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-26 23:31:19,095:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=2.719e+01, with an active set of 63 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:19,104:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=2.000e+01, with an active set of 73 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:19,105:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=2.000e+01, with an active set of 73 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:19,115:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.500e+01, with an active set of 66 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:19,117:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=1.359e+01, with an active set of 83 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:19,121:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=2.189e+01, with an active set of 68 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:19,121:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=2.149e+01, with an active set of 68 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:19,127:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 87 iterations, i.e. alpha=1.863e+01, with an active set of 75 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:19,129:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.010e+01, with an active set of 98 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:19,130:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=9.935e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:19,135:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 121 iterations, alpha=8.780e+00, previous alpha=8.633e+00, with an active set of 102 regressors.
  warnings.warn(

2022-09-26 23:31:19,139:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=1.054e+01, with an active set of 92 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:19,143:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 110 iterations, alpha=1.051e+01, previous alpha=9.486e+00, with an active set of 95 regressors.
  warnings.warn(

2022-09-26 23:31:19,145:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=3.123e+01, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:19,149:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=2.778e+01, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:19,153:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=2.573e+01, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:19,154:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.484e+01, with an active set of 68 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:19,165:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=1.515e+01, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:19,174:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 104 iterations, alpha=1.226e+01, previous alpha=1.174e+01, with an active set of 95 regressors.
  warnings.warn(

2022-09-26 23:31:20,220:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-26 23:31:20,220:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-26 23:31:20,244:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=4.521e+01, with an active set of 54 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:20,253:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=2.013e+01, with an active set of 66 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:20,258:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=1.724e+01, with an active set of 70 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:20,261:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=2.201e+01, with an active set of 72 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:20,261:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=1.942e+01, with an active set of 77 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:20,261:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 93 iterations, alpha=1.896e+01, previous alpha=1.884e+01, with an active set of 78 regressors.
  warnings.warn(

2022-09-26 23:31:20,269:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=1.026e+01, with an active set of 94 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:20,269:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=8.809e+00, with an active set of 97 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:20,274:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=7.976e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:31:20,275:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 112 iterations, alpha=7.851e+00, previous alpha=7.579e+00, with an active set of 101 regressors.
  warnings.warn(

2022-09-26 23:31:20,603:INFO:Calculating mean and std
2022-09-26 23:31:20,606:INFO:Creating metrics dataframe
2022-09-26 23:31:20,611:INFO:Uploading results into container
2022-09-26 23:31:20,611:INFO:Uploading model into container now
2022-09-26 23:31:20,611:INFO:master_model_container: 6
2022-09-26 23:31:20,611:INFO:display_container: 2
2022-09-26 23:31:20,611:INFO:LassoLars(random_state=123)
2022-09-26 23:31:20,611:INFO:create_model() successfully completed......................................
2022-09-26 23:31:20,777:INFO:SubProcess create_model() end ==================================
2022-09-26 23:31:20,777:INFO:Creating metrics dataframe
2022-09-26 23:31:20,804:INFO:Initializing Orthogonal Matching Pursuit
2022-09-26 23:31:20,804:INFO:Total runtime is 0.8643001317977906 minutes
2022-09-26 23:31:20,808:INFO:SubProcess create_model() called ==================================
2022-09-26 23:31:20,808:INFO:Initializing create_model()
2022-09-26 23:31:20,808:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDA934BC70>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ED934F5D30>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:31:20,808:INFO:Checking exceptions
2022-09-26 23:31:20,808:INFO:Importing libraries
2022-09-26 23:31:20,824:INFO:Copying training dataset
2022-09-26 23:31:20,826:INFO:Defining folds
2022-09-26 23:31:20,826:INFO:Declaring metric variables
2022-09-26 23:31:20,840:INFO:Importing untrained model
2022-09-26 23:31:20,856:INFO:Orthogonal Matching Pursuit Imported successfully
2022-09-26 23:31:20,871:INFO:Starting cross validation
2022-09-26 23:31:20,887:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:31:22,053:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:31:22,076:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:31:22,112:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:31:22,127:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:31:22,140:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:31:22,171:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:31:22,171:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:31:22,203:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:31:23,348:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:31:23,429:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:31:23,796:INFO:Calculating mean and std
2022-09-26 23:31:23,806:INFO:Creating metrics dataframe
2022-09-26 23:31:23,806:INFO:Uploading results into container
2022-09-26 23:31:23,806:INFO:Uploading model into container now
2022-09-26 23:31:23,806:INFO:master_model_container: 7
2022-09-26 23:31:23,806:INFO:display_container: 2
2022-09-26 23:31:23,806:INFO:OrthogonalMatchingPursuit()
2022-09-26 23:31:23,806:INFO:create_model() successfully completed......................................
2022-09-26 23:31:23,982:INFO:SubProcess create_model() end ==================================
2022-09-26 23:31:23,982:INFO:Creating metrics dataframe
2022-09-26 23:31:23,998:INFO:Initializing Bayesian Ridge
2022-09-26 23:31:23,998:INFO:Total runtime is 0.9175311088562013 minutes
2022-09-26 23:31:23,998:INFO:SubProcess create_model() called ==================================
2022-09-26 23:31:24,013:INFO:Initializing create_model()
2022-09-26 23:31:24,013:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDA934BC70>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ED934F5D30>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:31:24,013:INFO:Checking exceptions
2022-09-26 23:31:24,022:INFO:Importing libraries
2022-09-26 23:31:24,022:INFO:Copying training dataset
2022-09-26 23:31:24,045:INFO:Defining folds
2022-09-26 23:31:24,047:INFO:Declaring metric variables
2022-09-26 23:31:24,054:INFO:Importing untrained model
2022-09-26 23:31:24,076:INFO:Bayesian Ridge Imported successfully
2022-09-26 23:31:24,096:INFO:Starting cross validation
2022-09-26 23:31:24,113:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:31:27,046:INFO:Calculating mean and std
2022-09-26 23:31:27,054:INFO:Creating metrics dataframe
2022-09-26 23:31:27,062:INFO:Uploading results into container
2022-09-26 23:31:27,062:INFO:Uploading model into container now
2022-09-26 23:31:27,062:INFO:master_model_container: 8
2022-09-26 23:31:27,062:INFO:display_container: 2
2022-09-26 23:31:27,062:INFO:BayesianRidge()
2022-09-26 23:31:27,070:INFO:create_model() successfully completed......................................
2022-09-26 23:31:27,233:INFO:SubProcess create_model() end ==================================
2022-09-26 23:31:27,233:INFO:Creating metrics dataframe
2022-09-26 23:31:27,255:INFO:Initializing Passive Aggressive Regressor
2022-09-26 23:31:27,259:INFO:Total runtime is 0.9718880653381349 minutes
2022-09-26 23:31:27,264:INFO:SubProcess create_model() called ==================================
2022-09-26 23:31:27,264:INFO:Initializing create_model()
2022-09-26 23:31:27,264:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDA934BC70>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ED934F5D30>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:31:27,264:INFO:Checking exceptions
2022-09-26 23:31:27,272:INFO:Importing libraries
2022-09-26 23:31:27,272:INFO:Copying training dataset
2022-09-26 23:31:27,288:INFO:Defining folds
2022-09-26 23:31:27,288:INFO:Declaring metric variables
2022-09-26 23:31:27,296:INFO:Importing untrained model
2022-09-26 23:31:27,312:INFO:Passive Aggressive Regressor Imported successfully
2022-09-26 23:31:27,333:INFO:Starting cross validation
2022-09-26 23:31:27,344:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:31:31,207:INFO:Calculating mean and std
2022-09-26 23:31:31,207:INFO:Creating metrics dataframe
2022-09-26 23:31:31,223:INFO:Uploading results into container
2022-09-26 23:31:31,223:INFO:Uploading model into container now
2022-09-26 23:31:31,223:INFO:master_model_container: 9
2022-09-26 23:31:31,223:INFO:display_container: 2
2022-09-26 23:31:31,223:INFO:PassiveAggressiveRegressor(random_state=123)
2022-09-26 23:31:31,223:INFO:create_model() successfully completed......................................
2022-09-26 23:31:31,383:INFO:SubProcess create_model() end ==================================
2022-09-26 23:31:31,383:INFO:Creating metrics dataframe
2022-09-26 23:31:31,412:INFO:Initializing Huber Regressor
2022-09-26 23:31:31,412:INFO:Total runtime is 1.0411083380381267 minutes
2022-09-26 23:31:31,412:INFO:SubProcess create_model() called ==================================
2022-09-26 23:31:31,412:INFO:Initializing create_model()
2022-09-26 23:31:31,412:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDA934BC70>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ED934F5D30>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:31:31,412:INFO:Checking exceptions
2022-09-26 23:31:31,432:INFO:Importing libraries
2022-09-26 23:31:31,432:INFO:Copying training dataset
2022-09-26 23:31:31,444:INFO:Defining folds
2022-09-26 23:31:31,444:INFO:Declaring metric variables
2022-09-26 23:31:31,460:INFO:Importing untrained model
2022-09-26 23:31:31,460:INFO:Huber Regressor Imported successfully
2022-09-26 23:31:31,486:INFO:Starting cross validation
2022-09-26 23:31:31,492:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:31:33,964:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-26 23:31:35,847:INFO:Calculating mean and std
2022-09-26 23:31:35,855:INFO:Creating metrics dataframe
2022-09-26 23:31:35,863:INFO:Uploading results into container
2022-09-26 23:31:35,865:INFO:Uploading model into container now
2022-09-26 23:31:35,867:INFO:master_model_container: 10
2022-09-26 23:31:35,867:INFO:display_container: 2
2022-09-26 23:31:35,870:INFO:HuberRegressor()
2022-09-26 23:31:35,870:INFO:create_model() successfully completed......................................
2022-09-26 23:31:36,100:INFO:SubProcess create_model() end ==================================
2022-09-26 23:31:36,100:INFO:Creating metrics dataframe
2022-09-26 23:31:36,131:INFO:Initializing K Neighbors Regressor
2022-09-26 23:31:36,131:INFO:Total runtime is 1.1197606086730958 minutes
2022-09-26 23:31:36,141:INFO:SubProcess create_model() called ==================================
2022-09-26 23:31:36,141:INFO:Initializing create_model()
2022-09-26 23:31:36,141:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDA934BC70>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ED934F5D30>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:31:36,141:INFO:Checking exceptions
2022-09-26 23:31:36,156:INFO:Importing libraries
2022-09-26 23:31:36,156:INFO:Copying training dataset
2022-09-26 23:31:36,181:INFO:Defining folds
2022-09-26 23:31:36,181:INFO:Declaring metric variables
2022-09-26 23:31:36,197:INFO:Importing untrained model
2022-09-26 23:31:36,213:INFO:K Neighbors Regressor Imported successfully
2022-09-26 23:31:36,238:INFO:Starting cross validation
2022-09-26 23:31:36,254:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:31:39,700:INFO:Calculating mean and std
2022-09-26 23:31:39,700:INFO:Creating metrics dataframe
2022-09-26 23:31:39,707:INFO:Uploading results into container
2022-09-26 23:31:39,715:INFO:Uploading model into container now
2022-09-26 23:31:39,715:INFO:master_model_container: 11
2022-09-26 23:31:39,715:INFO:display_container: 2
2022-09-26 23:31:39,715:INFO:KNeighborsRegressor(n_jobs=-1)
2022-09-26 23:31:39,715:INFO:create_model() successfully completed......................................
2022-09-26 23:31:39,902:INFO:SubProcess create_model() end ==================================
2022-09-26 23:31:39,902:INFO:Creating metrics dataframe
2022-09-26 23:31:39,944:INFO:Initializing Decision Tree Regressor
2022-09-26 23:31:39,944:INFO:Total runtime is 1.1832992752393088 minutes
2022-09-26 23:31:39,957:INFO:SubProcess create_model() called ==================================
2022-09-26 23:31:39,960:INFO:Initializing create_model()
2022-09-26 23:31:39,960:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDA934BC70>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ED934F5D30>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:31:39,960:INFO:Checking exceptions
2022-09-26 23:31:39,969:INFO:Importing libraries
2022-09-26 23:31:39,969:INFO:Copying training dataset
2022-09-26 23:31:40,003:INFO:Defining folds
2022-09-26 23:31:40,003:INFO:Declaring metric variables
2022-09-26 23:31:40,018:INFO:Importing untrained model
2022-09-26 23:31:40,034:INFO:Decision Tree Regressor Imported successfully
2022-09-26 23:31:40,063:INFO:Starting cross validation
2022-09-26 23:31:40,077:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:31:43,318:INFO:Calculating mean and std
2022-09-26 23:31:43,318:INFO:Creating metrics dataframe
2022-09-26 23:31:43,322:INFO:Uploading results into container
2022-09-26 23:31:43,322:INFO:Uploading model into container now
2022-09-26 23:31:43,322:INFO:master_model_container: 12
2022-09-26 23:31:43,322:INFO:display_container: 2
2022-09-26 23:31:43,322:INFO:DecisionTreeRegressor(random_state=123)
2022-09-26 23:31:43,322:INFO:create_model() successfully completed......................................
2022-09-26 23:31:43,531:INFO:SubProcess create_model() end ==================================
2022-09-26 23:31:43,531:INFO:Creating metrics dataframe
2022-09-26 23:31:43,567:INFO:Initializing Random Forest Regressor
2022-09-26 23:31:43,567:INFO:Total runtime is 1.2436813990275066 minutes
2022-09-26 23:31:43,580:INFO:SubProcess create_model() called ==================================
2022-09-26 23:31:43,580:INFO:Initializing create_model()
2022-09-26 23:31:43,580:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDA934BC70>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ED934F5D30>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:31:43,580:INFO:Checking exceptions
2022-09-26 23:31:43,590:INFO:Importing libraries
2022-09-26 23:31:43,592:INFO:Copying training dataset
2022-09-26 23:31:43,613:INFO:Defining folds
2022-09-26 23:31:43,613:INFO:Declaring metric variables
2022-09-26 23:31:43,625:INFO:Importing untrained model
2022-09-26 23:31:43,638:INFO:Random Forest Regressor Imported successfully
2022-09-26 23:31:43,661:INFO:Starting cross validation
2022-09-26 23:31:43,670:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:31:54,128:INFO:Calculating mean and std
2022-09-26 23:31:54,133:INFO:Creating metrics dataframe
2022-09-26 23:31:54,141:INFO:Uploading results into container
2022-09-26 23:31:54,150:INFO:Uploading model into container now
2022-09-26 23:31:54,158:INFO:master_model_container: 13
2022-09-26 23:31:54,158:INFO:display_container: 2
2022-09-26 23:31:54,158:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-09-26 23:31:54,158:INFO:create_model() successfully completed......................................
2022-09-26 23:31:54,465:INFO:SubProcess create_model() end ==================================
2022-09-26 23:31:54,465:INFO:Creating metrics dataframe
2022-09-26 23:31:54,514:INFO:Initializing Extra Trees Regressor
2022-09-26 23:31:54,515:INFO:Total runtime is 1.426155455907186 minutes
2022-09-26 23:31:54,530:INFO:SubProcess create_model() called ==================================
2022-09-26 23:31:54,530:INFO:Initializing create_model()
2022-09-26 23:31:54,533:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDA934BC70>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ED934F5D30>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:31:54,533:INFO:Checking exceptions
2022-09-26 23:31:54,548:INFO:Importing libraries
2022-09-26 23:31:54,548:INFO:Copying training dataset
2022-09-26 23:31:54,571:INFO:Defining folds
2022-09-26 23:31:54,571:INFO:Declaring metric variables
2022-09-26 23:31:54,587:INFO:Importing untrained model
2022-09-26 23:31:54,600:INFO:Extra Trees Regressor Imported successfully
2022-09-26 23:31:54,622:INFO:Starting cross validation
2022-09-26 23:31:54,639:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:32:02,758:INFO:Calculating mean and std
2022-09-26 23:32:02,762:INFO:Creating metrics dataframe
2022-09-26 23:32:02,767:INFO:Uploading results into container
2022-09-26 23:32:02,767:INFO:Uploading model into container now
2022-09-26 23:32:02,768:INFO:master_model_container: 14
2022-09-26 23:32:02,768:INFO:display_container: 2
2022-09-26 23:32:02,768:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-09-26 23:32:02,768:INFO:create_model() successfully completed......................................
2022-09-26 23:32:03,096:INFO:SubProcess create_model() end ==================================
2022-09-26 23:32:03,096:INFO:Creating metrics dataframe
2022-09-26 23:32:03,147:INFO:Initializing AdaBoost Regressor
2022-09-26 23:32:03,147:INFO:Total runtime is 1.5700193643569949 minutes
2022-09-26 23:32:03,160:INFO:SubProcess create_model() called ==================================
2022-09-26 23:32:03,160:INFO:Initializing create_model()
2022-09-26 23:32:03,161:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDA934BC70>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ED934F5D30>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:32:03,161:INFO:Checking exceptions
2022-09-26 23:32:03,170:INFO:Importing libraries
2022-09-26 23:32:03,170:INFO:Copying training dataset
2022-09-26 23:32:03,194:INFO:Defining folds
2022-09-26 23:32:03,194:INFO:Declaring metric variables
2022-09-26 23:32:03,210:INFO:Importing untrained model
2022-09-26 23:32:03,235:INFO:AdaBoost Regressor Imported successfully
2022-09-26 23:32:03,267:INFO:Starting cross validation
2022-09-26 23:32:03,276:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:32:08,520:INFO:Calculating mean and std
2022-09-26 23:32:08,520:INFO:Creating metrics dataframe
2022-09-26 23:32:08,528:INFO:Uploading results into container
2022-09-26 23:32:08,537:INFO:Uploading model into container now
2022-09-26 23:32:08,537:INFO:master_model_container: 15
2022-09-26 23:32:08,537:INFO:display_container: 2
2022-09-26 23:32:08,537:INFO:AdaBoostRegressor(random_state=123)
2022-09-26 23:32:08,537:INFO:create_model() successfully completed......................................
2022-09-26 23:32:08,807:INFO:SubProcess create_model() end ==================================
2022-09-26 23:32:08,807:INFO:Creating metrics dataframe
2022-09-26 23:32:08,878:INFO:Initializing Gradient Boosting Regressor
2022-09-26 23:32:08,878:INFO:Total runtime is 1.6655310153961185 minutes
2022-09-26 23:32:08,896:INFO:SubProcess create_model() called ==================================
2022-09-26 23:32:08,898:INFO:Initializing create_model()
2022-09-26 23:32:08,898:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDA934BC70>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ED934F5D30>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:32:08,898:INFO:Checking exceptions
2022-09-26 23:32:08,913:INFO:Importing libraries
2022-09-26 23:32:08,913:INFO:Copying training dataset
2022-09-26 23:32:08,941:INFO:Defining folds
2022-09-26 23:32:08,941:INFO:Declaring metric variables
2022-09-26 23:32:08,954:INFO:Importing untrained model
2022-09-26 23:32:08,970:INFO:Gradient Boosting Regressor Imported successfully
2022-09-26 23:32:08,995:INFO:Starting cross validation
2022-09-26 23:32:09,011:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:32:15,508:INFO:Calculating mean and std
2022-09-26 23:32:15,516:INFO:Creating metrics dataframe
2022-09-26 23:32:15,525:INFO:Uploading results into container
2022-09-26 23:32:15,529:INFO:Uploading model into container now
2022-09-26 23:32:15,533:INFO:master_model_container: 16
2022-09-26 23:32:15,533:INFO:display_container: 2
2022-09-26 23:32:15,533:INFO:GradientBoostingRegressor(random_state=123)
2022-09-26 23:32:15,533:INFO:create_model() successfully completed......................................
2022-09-26 23:32:15,836:INFO:SubProcess create_model() end ==================================
2022-09-26 23:32:15,836:INFO:Creating metrics dataframe
2022-09-26 23:32:15,865:INFO:Initializing Light Gradient Boosting Machine
2022-09-26 23:32:15,865:INFO:Total runtime is 1.7819878737131758 minutes
2022-09-26 23:32:15,866:INFO:SubProcess create_model() called ==================================
2022-09-26 23:32:15,866:INFO:Initializing create_model()
2022-09-26 23:32:15,866:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDA934BC70>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ED934F5D30>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:32:15,874:INFO:Checking exceptions
2022-09-26 23:32:15,882:INFO:Importing libraries
2022-09-26 23:32:15,882:INFO:Copying training dataset
2022-09-26 23:32:15,899:INFO:Defining folds
2022-09-26 23:32:15,907:INFO:Declaring metric variables
2022-09-26 23:32:15,917:INFO:Importing untrained model
2022-09-26 23:32:15,931:INFO:Light Gradient Boosting Machine Imported successfully
2022-09-26 23:32:15,961:INFO:Starting cross validation
2022-09-26 23:32:15,971:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:32:20,756:INFO:Calculating mean and std
2022-09-26 23:32:20,764:INFO:Creating metrics dataframe
2022-09-26 23:32:20,764:INFO:Uploading results into container
2022-09-26 23:32:20,772:INFO:Uploading model into container now
2022-09-26 23:32:20,772:INFO:master_model_container: 17
2022-09-26 23:32:20,772:INFO:display_container: 2
2022-09-26 23:32:20,772:INFO:LGBMRegressor(random_state=123)
2022-09-26 23:32:20,772:INFO:create_model() successfully completed......................................
2022-09-26 23:32:20,975:INFO:SubProcess create_model() end ==================================
2022-09-26 23:32:20,975:INFO:Creating metrics dataframe
2022-09-26 23:32:21,009:INFO:Initializing Dummy Regressor
2022-09-26 23:32:21,009:INFO:Total runtime is 1.867726254463196 minutes
2022-09-26 23:32:21,020:INFO:SubProcess create_model() called ==================================
2022-09-26 23:32:21,020:INFO:Initializing create_model()
2022-09-26 23:32:21,020:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDA934BC70>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ED934F5D30>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:32:21,020:INFO:Checking exceptions
2022-09-26 23:32:21,030:INFO:Importing libraries
2022-09-26 23:32:21,030:INFO:Copying training dataset
2022-09-26 23:32:21,044:INFO:Defining folds
2022-09-26 23:32:21,044:INFO:Declaring metric variables
2022-09-26 23:32:21,054:INFO:Importing untrained model
2022-09-26 23:32:21,061:INFO:Dummy Regressor Imported successfully
2022-09-26 23:32:21,077:INFO:Starting cross validation
2022-09-26 23:32:21,093:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:32:23,127:INFO:Calculating mean and std
2022-09-26 23:32:23,131:INFO:Creating metrics dataframe
2022-09-26 23:32:23,140:INFO:Uploading results into container
2022-09-26 23:32:23,143:INFO:Uploading model into container now
2022-09-26 23:32:23,144:INFO:master_model_container: 18
2022-09-26 23:32:23,145:INFO:display_container: 2
2022-09-26 23:32:23,145:INFO:DummyRegressor()
2022-09-26 23:32:23,145:INFO:create_model() successfully completed......................................
2022-09-26 23:32:23,357:INFO:SubProcess create_model() end ==================================
2022-09-26 23:32:23,360:INFO:Creating metrics dataframe
2022-09-26 23:32:23,411:INFO:Initializing create_model()
2022-09-26 23:32:23,411:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDA934BC70>, estimator=PassiveAggressiveRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:32:23,411:INFO:Checking exceptions
2022-09-26 23:32:23,427:INFO:Importing libraries
2022-09-26 23:32:23,427:INFO:Copying training dataset
2022-09-26 23:32:23,445:INFO:Defining folds
2022-09-26 23:32:23,445:INFO:Declaring metric variables
2022-09-26 23:32:23,445:INFO:Importing untrained model
2022-09-26 23:32:23,445:INFO:Declaring custom model
2022-09-26 23:32:23,445:INFO:Passive Aggressive Regressor Imported successfully
2022-09-26 23:32:23,463:INFO:Cross validation set to False
2022-09-26 23:32:23,463:INFO:Fitting Model
2022-09-26 23:32:26,916:INFO:PassiveAggressiveRegressor(random_state=123)
2022-09-26 23:32:26,916:INFO:create_model() successfully completed......................................
2022-09-26 23:32:27,247:INFO:master_model_container: 18
2022-09-26 23:32:27,247:INFO:display_container: 2
2022-09-26 23:32:27,247:INFO:PassiveAggressiveRegressor(random_state=123)
2022-09-26 23:32:27,247:INFO:compare_models() successfully completed......................................
2022-09-26 23:34:49,764:INFO:Initializing create_model()
2022-09-26 23:34:49,764:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDA934BC70>, estimator=par, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:34:49,764:INFO:Checking exceptions
2022-09-26 23:34:49,849:INFO:Importing libraries
2022-09-26 23:34:49,849:INFO:Copying training dataset
2022-09-26 23:34:49,879:INFO:Defining folds
2022-09-26 23:34:49,879:INFO:Declaring metric variables
2022-09-26 23:34:49,894:INFO:Importing untrained model
2022-09-26 23:34:49,907:INFO:Passive Aggressive Regressor Imported successfully
2022-09-26 23:34:49,933:INFO:Starting cross validation
2022-09-26 23:34:49,955:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:34:53,479:INFO:Calculating mean and std
2022-09-26 23:34:53,486:INFO:Creating metrics dataframe
2022-09-26 23:34:53,509:INFO:Finalizing model
2022-09-26 23:34:55,252:INFO:Uploading results into container
2022-09-26 23:34:55,253:INFO:Uploading model into container now
2022-09-26 23:34:55,266:INFO:master_model_container: 19
2022-09-26 23:34:55,268:INFO:display_container: 3
2022-09-26 23:34:55,268:INFO:PassiveAggressiveRegressor(random_state=123)
2022-09-26 23:34:55,268:INFO:create_model() successfully completed......................................
2022-09-26 23:37:03,234:INFO:Initializing tune_model()
2022-09-26 23:37:03,234:INFO:tune_model(estimator=PassiveAggressiveRegressor(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDA934BC70>)
2022-09-26 23:37:03,234:INFO:Checking exceptions
2022-09-26 23:37:03,321:INFO:Copying training dataset
2022-09-26 23:37:03,346:INFO:Checking base model
2022-09-26 23:37:03,346:INFO:Base model : Passive Aggressive Regressor
2022-09-26 23:37:03,359:INFO:Declaring metric variables
2022-09-26 23:37:03,362:INFO:Defining Hyperparameters
2022-09-26 23:37:03,635:INFO:Tuning with n_jobs=-1
2022-09-26 23:37:03,635:INFO:Initializing RandomizedSearchCV
2022-09-26 23:37:06,264:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2022-09-26 23:37:06,298:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2022-09-26 23:37:06,385:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2022-09-26 23:37:06,481:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2022-09-26 23:37:08,918:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2022-09-26 23:37:09,117:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2022-09-26 23:37:24,062:INFO:best_params: {'actual_estimator__shuffle': False, 'actual_estimator__loss': 'epsilon_insensitive', 'actual_estimator__fit_intercept': True, 'actual_estimator__epsilon': 0.4, 'actual_estimator__C': 2.129}
2022-09-26 23:37:24,062:INFO:Hyperparameter search completed
2022-09-26 23:37:24,062:INFO:SubProcess create_model() called ==================================
2022-09-26 23:37:24,062:INFO:Initializing create_model()
2022-09-26 23:37:24,062:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDA934BC70>, estimator=PassiveAggressiveRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ED81544DF0>, model_only=True, return_train_score=False, kwargs={'shuffle': False, 'loss': 'epsilon_insensitive', 'fit_intercept': True, 'epsilon': 0.4, 'C': 2.129})
2022-09-26 23:37:24,062:INFO:Checking exceptions
2022-09-26 23:37:24,070:INFO:Importing libraries
2022-09-26 23:37:24,070:INFO:Copying training dataset
2022-09-26 23:37:24,086:INFO:Defining folds
2022-09-26 23:37:24,086:INFO:Declaring metric variables
2022-09-26 23:37:24,086:INFO:Importing untrained model
2022-09-26 23:37:24,086:INFO:Declaring custom model
2022-09-26 23:37:24,108:INFO:Passive Aggressive Regressor Imported successfully
2022-09-26 23:37:24,149:INFO:Starting cross validation
2022-09-26 23:37:24,165:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:37:26,861:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2022-09-26 23:37:26,946:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2022-09-26 23:37:26,957:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2022-09-26 23:37:26,957:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2022-09-26 23:37:28,878:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2022-09-26 23:37:29,064:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2022-09-26 23:37:29,402:INFO:Calculating mean and std
2022-09-26 23:37:29,402:INFO:Creating metrics dataframe
2022-09-26 23:37:29,418:INFO:Finalizing model
2022-09-26 23:37:31,687:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(
2022-09-26 23:37:31,703:INFO:Uploading results into container
2022-09-26 23:37:31,703:INFO:Uploading model into container now
2022-09-26 23:37:31,703:INFO:master_model_container: 20
2022-09-26 23:37:31,711:INFO:display_container: 4
2022-09-26 23:37:31,711:INFO:PassiveAggressiveRegressor(C=2.129, epsilon=0.4, random_state=123,
                           shuffle=False)
2022-09-26 23:37:31,711:INFO:create_model() successfully completed......................................
2022-09-26 23:37:31,889:INFO:SubProcess create_model() end ==================================
2022-09-26 23:37:31,889:INFO:choose_better activated
2022-09-26 23:37:31,897:INFO:SubProcess create_model() called ==================================
2022-09-26 23:37:31,905:INFO:Initializing create_model()
2022-09-26 23:37:31,905:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDA934BC70>, estimator=PassiveAggressiveRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:37:31,905:INFO:Checking exceptions
2022-09-26 23:37:31,921:INFO:Importing libraries
2022-09-26 23:37:31,921:INFO:Copying training dataset
2022-09-26 23:37:31,945:INFO:Defining folds
2022-09-26 23:37:31,945:INFO:Declaring metric variables
2022-09-26 23:37:31,945:INFO:Importing untrained model
2022-09-26 23:37:31,945:INFO:Declaring custom model
2022-09-26 23:37:31,953:INFO:Passive Aggressive Regressor Imported successfully
2022-09-26 23:37:31,953:INFO:Starting cross validation
2022-09-26 23:37:31,970:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:37:35,972:INFO:Calculating mean and std
2022-09-26 23:37:35,972:INFO:Creating metrics dataframe
2022-09-26 23:37:35,988:INFO:Finalizing model
2022-09-26 23:37:37,136:INFO:Uploading results into container
2022-09-26 23:37:37,136:INFO:Uploading model into container now
2022-09-26 23:37:37,136:INFO:master_model_container: 21
2022-09-26 23:37:37,136:INFO:display_container: 5
2022-09-26 23:37:37,136:INFO:PassiveAggressiveRegressor(random_state=123)
2022-09-26 23:37:37,136:INFO:create_model() successfully completed......................................
2022-09-26 23:37:37,292:INFO:SubProcess create_model() end ==================================
2022-09-26 23:37:37,292:INFO:PassiveAggressiveRegressor(random_state=123) result for R2 is 0.8222
2022-09-26 23:37:37,292:INFO:PassiveAggressiveRegressor(C=2.129, epsilon=0.4, random_state=123,
                           shuffle=False) result for R2 is 0.814
2022-09-26 23:37:37,292:INFO:PassiveAggressiveRegressor(random_state=123) is best model
2022-09-26 23:37:37,292:INFO:choose_better completed
2022-09-26 23:37:37,292:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2022-09-26 23:37:37,324:INFO:master_model_container: 21
2022-09-26 23:37:37,324:INFO:display_container: 4
2022-09-26 23:37:37,324:INFO:PassiveAggressiveRegressor(random_state=123)
2022-09-26 23:37:37,324:INFO:tune_model() successfully completed......................................
2022-09-26 23:40:38,599:INFO:PyCaret RegressionExperiment
2022-09-26 23:40:38,599:INFO:Logging name: reg-default-name
2022-09-26 23:40:38,599:INFO:ML Usecase: MLUsecase.REGRESSION
2022-09-26 23:40:38,599:INFO:version 3.0.0.rc4
2022-09-26 23:40:38,599:INFO:Initializing setup()
2022-09-26 23:40:38,599:INFO:self.USI: a69e
2022-09-26 23:40:38,599:INFO:self.variable_keys: {'y_test', '_available_plots', 'gpu_param', 'fold_groups_param', 'data', 'memory', 'target_param', 'idx', 'seed', 'log_plots_param', 'fold_generator', 'transform_target_param', 'exp_id', 'pipeline', 'X_test', 'X', 'fold_shuffle_param', 'USI', 'y_train', 'variable_keys', 'logging_param', 'n_jobs_param', 'display_container', 'html_param', 'master_model_container', '_gpu_n_jobs_param', '_ml_usecase', '_all_models_internal', 'X_train', 'transform_target_method_param', 'y', '_all_models', 'exp_name_log', '_all_metrics'}
2022-09-26 23:40:38,599:INFO:Checking environment
2022-09-26 23:40:38,599:INFO:python_version: 3.9.7
2022-09-26 23:40:38,599:INFO:python_build: ('tags/v3.9.7:1016ef3', 'Aug 30 2021 20:19:38')
2022-09-26 23:40:38,599:INFO:machine: AMD64
2022-09-26 23:40:38,599:INFO:platform: Windows-10-10.0.22622-SP0
2022-09-26 23:40:38,599:INFO:Memory: svmem(total=8416038912, available=1014386688, percent=87.9, used=7401652224, free=1014386688)
2022-09-26 23:40:38,599:INFO:Physical Core: 4
2022-09-26 23:40:38,605:INFO:Logical Core: 8
2022-09-26 23:40:38,605:INFO:Checking libraries
2022-09-26 23:40:38,605:INFO:System:
2022-09-26 23:40:38,605:INFO:    python: 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]
2022-09-26 23:40:38,605:INFO:executable: c:\Users\HP\AppData\Local\Programs\Python\Python39\python.exe
2022-09-26 23:40:38,605:INFO:   machine: Windows-10-10.0.22622-SP0
2022-09-26 23:40:38,605:INFO:PyCaret required dependencies:
2022-09-26 23:40:38,605:INFO:                 pip: 22.2.2
2022-09-26 23:40:38,605:INFO:          setuptools: 57.4.0
2022-09-26 23:40:38,605:INFO:             pycaret: 3.0.0rc4
2022-09-26 23:40:38,605:INFO:             IPython: 8.4.0
2022-09-26 23:40:38,605:INFO:          ipywidgets: 8.0.2
2022-09-26 23:40:38,605:INFO:                tqdm: 4.64.0
2022-09-26 23:40:38,605:INFO:               numpy: 1.22.4
2022-09-26 23:40:38,605:INFO:              pandas: 1.4.2
2022-09-26 23:40:38,605:INFO:              jinja2: 3.1.2
2022-09-26 23:40:38,605:INFO:               scipy: 1.8.1
2022-09-26 23:40:38,605:INFO:              joblib: 1.1.0
2022-09-26 23:40:38,605:INFO:             sklearn: 1.1.2
2022-09-26 23:40:38,608:INFO:                pyod: 1.0.5
2022-09-26 23:40:38,608:INFO:            imblearn: 0.9.1
2022-09-26 23:40:38,608:INFO:   category_encoders: 2.5.0
2022-09-26 23:40:38,608:INFO:            lightgbm: 3.3.2
2022-09-26 23:40:38,608:INFO:               numba: 0.55.2
2022-09-26 23:40:38,608:INFO:            requests: 2.28.1
2022-09-26 23:40:38,608:INFO:          matplotlib: 3.5.3
2022-09-26 23:40:38,608:INFO:          scikitplot: 0.3.7
2022-09-26 23:40:38,608:INFO:         yellowbrick: 1.5
2022-09-26 23:40:38,610:INFO:              plotly: 5.10.0
2022-09-26 23:40:38,610:INFO:             kaleido: 0.2.1
2022-09-26 23:40:38,610:INFO:         statsmodels: 0.13.2
2022-09-26 23:40:38,610:INFO:              sktime: 0.13.3
2022-09-26 23:40:38,610:INFO:               tbats: 1.1.0
2022-09-26 23:40:38,610:INFO:            pmdarima: 1.8.5
2022-09-26 23:40:38,610:INFO:              psutil: 5.9.1
2022-09-26 23:40:38,610:INFO:PyCaret optional dependencies:
2022-09-26 23:40:38,610:INFO:                shap: Not installed
2022-09-26 23:40:38,610:INFO:           interpret: Not installed
2022-09-26 23:40:38,610:INFO:                umap: Not installed
2022-09-26 23:40:38,610:INFO:    pandas_profiling: Not installed
2022-09-26 23:40:38,610:INFO:  explainerdashboard: Not installed
2022-09-26 23:40:38,610:INFO:             autoviz: Not installed
2022-09-26 23:40:38,610:INFO:           fairlearn: Not installed
2022-09-26 23:40:38,610:INFO:             xgboost: Not installed
2022-09-26 23:40:38,610:INFO:            catboost: Not installed
2022-09-26 23:40:38,610:INFO:              kmodes: Not installed
2022-09-26 23:40:38,610:INFO:             mlxtend: Not installed
2022-09-26 23:40:38,610:INFO:       statsforecast: Not installed
2022-09-26 23:40:38,610:INFO:        tune_sklearn: Not installed
2022-09-26 23:40:38,610:INFO:                 ray: Not installed
2022-09-26 23:40:38,610:INFO:            hyperopt: Not installed
2022-09-26 23:40:38,610:INFO:              optuna: Not installed
2022-09-26 23:40:38,610:INFO:               skopt: Not installed
2022-09-26 23:40:38,610:INFO:              mlflow: Not installed
2022-09-26 23:40:38,610:INFO:              gradio: Not installed
2022-09-26 23:40:38,614:INFO:             fastapi: Not installed
2022-09-26 23:40:38,614:INFO:             uvicorn: Not installed
2022-09-26 23:40:38,614:INFO:              m2cgen: Not installed
2022-09-26 23:40:38,614:INFO:           evidently: Not installed
2022-09-26 23:40:38,614:INFO:                nltk: Not installed
2022-09-26 23:40:38,614:INFO:            pyLDAvis: Not installed
2022-09-26 23:40:38,614:INFO:              gensim: Not installed
2022-09-26 23:40:38,614:INFO:               spacy: Not installed
2022-09-26 23:40:38,614:INFO:           wordcloud: Not installed
2022-09-26 23:40:38,614:INFO:            textblob: Not installed
2022-09-26 23:40:38,614:INFO:               fugue: Not installed
2022-09-26 23:40:38,614:INFO:           streamlit: Not installed
2022-09-26 23:40:38,616:INFO:             prophet: Not installed
2022-09-26 23:40:38,616:INFO:None
2022-09-26 23:40:38,616:INFO:Set up data.
2022-09-26 23:40:38,708:INFO:Set up train/test split.
2022-09-26 23:40:38,741:INFO:Set up index.
2022-09-26 23:40:38,741:INFO:Set up folding strategy.
2022-09-26 23:40:38,741:INFO:Assigning column types.
2022-09-26 23:40:38,752:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-09-26 23:40:38,752:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-09-26 23:40:38,757:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-26 23:40:38,773:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-26 23:40:38,887:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-26 23:40:38,979:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-26 23:40:38,979:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:40:38,979:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:40:38,979:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-09-26 23:40:38,988:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-26 23:40:38,999:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-26 23:40:39,096:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-26 23:40:39,192:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-26 23:40:39,192:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:40:39,192:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:40:39,192:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-09-26 23:40:39,203:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-26 23:40:39,208:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-26 23:40:39,306:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-26 23:40:39,372:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-26 23:40:39,372:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:40:39,372:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:40:39,380:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-26 23:40:39,396:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-26 23:40:39,510:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-26 23:40:39,574:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-26 23:40:39,574:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:40:39,574:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:40:39,574:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-09-26 23:40:39,591:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-26 23:40:39,684:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-26 23:40:39,753:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-26 23:40:39,753:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:40:39,753:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:40:39,770:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-26 23:40:39,882:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-26 23:40:39,988:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-26 23:40:39,988:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:40:39,990:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:40:39,990:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-09-26 23:40:40,201:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-26 23:40:40,275:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-26 23:40:40,275:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:40:40,275:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:40:40,393:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-26 23:40:40,468:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-26 23:40:40,468:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:40:40,468:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:40:40,468:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-09-26 23:40:40,586:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-26 23:40:40,658:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:40:40,658:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:40:40,780:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-26 23:40:40,870:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:40:40,871:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:40:40,871:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-09-26 23:40:41,075:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:40:41,075:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:40:41,274:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:40:41,274:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:40:41,274:INFO:Preparing preprocessing pipeline...
2022-09-26 23:40:41,278:INFO:Set up simple imputation.
2022-09-26 23:40:41,286:INFO:Set up encoding of ordinal features.
2022-09-26 23:40:41,294:INFO:Set up encoding of categorical features.
2022-09-26 23:40:41,294:INFO:Set up variance threshold.
2022-09-26 23:40:41,294:INFO:Set up feature normalization.
2022-09-26 23:41:31,364:INFO:PyCaret RegressionExperiment
2022-09-26 23:41:31,364:INFO:Logging name: reg-default-name
2022-09-26 23:41:31,369:INFO:ML Usecase: MLUsecase.REGRESSION
2022-09-26 23:41:31,369:INFO:version 3.0.0.rc4
2022-09-26 23:41:31,369:INFO:Initializing setup()
2022-09-26 23:41:31,369:INFO:self.USI: 15ac
2022-09-26 23:41:31,370:INFO:self.variable_keys: {'y_test', '_available_plots', 'gpu_param', 'fold_groups_param', 'data', 'memory', 'target_param', 'idx', 'seed', 'log_plots_param', 'fold_generator', 'transform_target_param', 'exp_id', 'pipeline', 'X_test', 'X', 'fold_shuffle_param', 'USI', 'y_train', 'variable_keys', 'logging_param', 'n_jobs_param', 'display_container', 'html_param', 'master_model_container', '_gpu_n_jobs_param', '_ml_usecase', '_all_models_internal', 'X_train', 'transform_target_method_param', 'y', '_all_models', 'exp_name_log', '_all_metrics'}
2022-09-26 23:41:31,370:INFO:Checking environment
2022-09-26 23:41:31,370:INFO:python_version: 3.9.7
2022-09-26 23:41:31,370:INFO:python_build: ('tags/v3.9.7:1016ef3', 'Aug 30 2021 20:19:38')
2022-09-26 23:41:31,370:INFO:machine: AMD64
2022-09-26 23:41:31,370:INFO:platform: Windows-10-10.0.22622-SP0
2022-09-26 23:41:31,371:INFO:Memory: svmem(total=8416038912, available=1165783040, percent=86.1, used=7250255872, free=1165783040)
2022-09-26 23:41:31,371:INFO:Physical Core: 4
2022-09-26 23:41:31,371:INFO:Logical Core: 8
2022-09-26 23:41:31,371:INFO:Checking libraries
2022-09-26 23:41:31,371:INFO:System:
2022-09-26 23:41:31,371:INFO:    python: 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]
2022-09-26 23:41:31,371:INFO:executable: c:\Users\HP\AppData\Local\Programs\Python\Python39\python.exe
2022-09-26 23:41:31,372:INFO:   machine: Windows-10-10.0.22622-SP0
2022-09-26 23:41:31,372:INFO:PyCaret required dependencies:
2022-09-26 23:41:31,372:INFO:                 pip: 22.2.2
2022-09-26 23:41:31,372:INFO:          setuptools: 57.4.0
2022-09-26 23:41:31,372:INFO:             pycaret: 3.0.0rc4
2022-09-26 23:41:31,372:INFO:             IPython: 8.4.0
2022-09-26 23:41:31,372:INFO:          ipywidgets: 8.0.2
2022-09-26 23:41:31,372:INFO:                tqdm: 4.64.0
2022-09-26 23:41:31,373:INFO:               numpy: 1.22.4
2022-09-26 23:41:31,373:INFO:              pandas: 1.4.2
2022-09-26 23:41:31,373:INFO:              jinja2: 3.1.2
2022-09-26 23:41:31,373:INFO:               scipy: 1.8.1
2022-09-26 23:41:31,373:INFO:              joblib: 1.1.0
2022-09-26 23:41:31,373:INFO:             sklearn: 1.1.2
2022-09-26 23:41:31,374:INFO:                pyod: 1.0.5
2022-09-26 23:41:31,374:INFO:            imblearn: 0.9.1
2022-09-26 23:41:31,374:INFO:   category_encoders: 2.5.0
2022-09-26 23:41:31,374:INFO:            lightgbm: 3.3.2
2022-09-26 23:41:31,375:INFO:               numba: 0.55.2
2022-09-26 23:41:31,375:INFO:            requests: 2.28.1
2022-09-26 23:41:31,375:INFO:          matplotlib: 3.5.3
2022-09-26 23:41:31,375:INFO:          scikitplot: 0.3.7
2022-09-26 23:41:31,376:INFO:         yellowbrick: 1.5
2022-09-26 23:41:31,376:INFO:              plotly: 5.10.0
2022-09-26 23:41:31,376:INFO:             kaleido: 0.2.1
2022-09-26 23:41:31,376:INFO:         statsmodels: 0.13.2
2022-09-26 23:41:31,377:INFO:              sktime: 0.13.3
2022-09-26 23:41:31,377:INFO:               tbats: 1.1.0
2022-09-26 23:41:31,377:INFO:            pmdarima: 1.8.5
2022-09-26 23:41:31,377:INFO:              psutil: 5.9.1
2022-09-26 23:41:31,377:INFO:PyCaret optional dependencies:
2022-09-26 23:41:31,377:INFO:                shap: Not installed
2022-09-26 23:41:31,377:INFO:           interpret: Not installed
2022-09-26 23:41:31,377:INFO:                umap: Not installed
2022-09-26 23:41:31,378:INFO:    pandas_profiling: Not installed
2022-09-26 23:41:31,378:INFO:  explainerdashboard: Not installed
2022-09-26 23:41:31,378:INFO:             autoviz: Not installed
2022-09-26 23:41:31,378:INFO:           fairlearn: Not installed
2022-09-26 23:41:31,378:INFO:             xgboost: Not installed
2022-09-26 23:41:31,378:INFO:            catboost: Not installed
2022-09-26 23:41:31,378:INFO:              kmodes: Not installed
2022-09-26 23:41:31,378:INFO:             mlxtend: Not installed
2022-09-26 23:41:31,378:INFO:       statsforecast: Not installed
2022-09-26 23:41:31,378:INFO:        tune_sklearn: Not installed
2022-09-26 23:41:31,378:INFO:                 ray: Not installed
2022-09-26 23:41:31,378:INFO:            hyperopt: Not installed
2022-09-26 23:41:31,378:INFO:              optuna: Not installed
2022-09-26 23:41:31,378:INFO:               skopt: Not installed
2022-09-26 23:41:31,380:INFO:              mlflow: Not installed
2022-09-26 23:41:31,380:INFO:              gradio: Not installed
2022-09-26 23:41:31,380:INFO:             fastapi: Not installed
2022-09-26 23:41:31,380:INFO:             uvicorn: Not installed
2022-09-26 23:41:31,380:INFO:              m2cgen: Not installed
2022-09-26 23:41:31,380:INFO:           evidently: Not installed
2022-09-26 23:41:31,380:INFO:                nltk: Not installed
2022-09-26 23:41:31,380:INFO:            pyLDAvis: Not installed
2022-09-26 23:41:31,380:INFO:              gensim: Not installed
2022-09-26 23:41:31,381:INFO:               spacy: Not installed
2022-09-26 23:41:31,381:INFO:           wordcloud: Not installed
2022-09-26 23:41:31,381:INFO:            textblob: Not installed
2022-09-26 23:41:31,381:INFO:               fugue: Not installed
2022-09-26 23:41:31,381:INFO:           streamlit: Not installed
2022-09-26 23:41:31,381:INFO:             prophet: Not installed
2022-09-26 23:41:31,381:INFO:None
2022-09-26 23:41:31,381:INFO:Set up data.
2022-09-26 23:41:31,506:INFO:Set up train/test split.
2022-09-26 23:41:31,537:INFO:Set up index.
2022-09-26 23:41:31,537:INFO:Set up folding strategy.
2022-09-26 23:41:31,537:INFO:Assigning column types.
2022-09-26 23:41:31,548:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-09-26 23:41:31,548:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-09-26 23:41:31,558:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-26 23:41:31,566:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-26 23:41:31,660:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-26 23:41:31,731:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-26 23:41:31,731:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:41:31,732:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:41:31,732:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-09-26 23:41:31,739:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-26 23:41:31,744:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-26 23:41:31,834:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-26 23:41:31,897:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-26 23:41:31,906:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:41:31,906:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:41:31,906:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-09-26 23:41:31,914:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-26 23:41:31,922:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-26 23:41:32,020:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-26 23:41:32,086:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-26 23:41:32,086:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:41:32,089:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:41:32,094:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-26 23:41:32,102:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-26 23:41:32,215:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-26 23:41:32,302:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-26 23:41:32,303:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:41:32,303:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:41:32,304:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-09-26 23:41:32,325:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-26 23:41:32,416:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-26 23:41:32,480:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-26 23:41:32,480:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:41:32,488:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:41:32,496:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-26 23:41:32,592:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-26 23:41:32,716:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-26 23:41:32,716:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:41:32,716:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:41:32,716:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-09-26 23:41:32,949:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-26 23:41:33,049:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-26 23:41:33,049:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:41:33,049:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:41:33,181:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-26 23:41:33,265:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-26 23:41:33,265:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:41:33,265:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:41:33,265:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-09-26 23:41:33,438:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-26 23:41:33,521:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:41:33,521:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:41:33,647:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-26 23:41:33,858:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:41:33,858:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:41:33,858:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-09-26 23:41:34,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:41:34,092:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:41:34,530:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:41:34,530:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:41:34,530:INFO:Preparing preprocessing pipeline...
2022-09-26 23:41:34,534:INFO:Set up simple imputation.
2022-09-26 23:41:34,546:INFO:Set up encoding of ordinal features.
2022-09-26 23:41:34,546:INFO:Set up encoding of categorical features.
2022-09-26 23:41:34,546:INFO:Set up variance threshold.
2022-09-26 23:41:34,554:INFO:Set up feature normalization.
2022-09-26 23:41:37,704:INFO:Finished creating preprocessing pipeline.
2022-09-26 23:41:37,744:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Id', 'MSSubClass', 'LotFrontage',
                                             'LotArea', 'OverallQual',
                                             'OverallCond', 'YearBuilt',
                                             'YearRemodAdd', 'MasVnrArea',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '1stFlrSF', '2ndFlrSF',
                                             'LowQualFinSF', 'GrLivArea',
                                             'BsmtFullBat...
                                                                         'Neighborhood',
                                                                         'Condition1',
                                                                         'Condition2',
                                                                         'HouseStyle',
                                                                         'RoofStyle',
                                                                         'RoofMatl',
                                                                         'Foundation',
                                                                         'BsmtFinType1',
                                                                         'BsmtFinType2',
                                                                         'Heating',
                                                                         'GarageType',
                                                                         'SaleCondition'],
                                                                   handle_missing='return_nan',
                                                                   random_state=2156))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2022-09-26 23:41:37,744:INFO:Creating final display dataframe.
2022-09-26 23:41:47,669:INFO:Setup display_container:                  Description             Value
0                 Session id              2156
1                     Target         SalePrice
2                Target type        Regression
3                 Data shape       (1460, 144)
4           Train data shape       (1021, 144)
5            Test data shape        (439, 144)
6            Ignore features                 6
7           Ordinal features                 2
8           Numeric features                37
9       Categorical features                37
10  Rows with missing values            100.0%
11                Preprocess              True
12           Imputation type            simple
13        Numeric imputation              mean
14    Categorical imputation          constant
15  Maximum one-hot encoding                 5
16           Encoding method              None
17    Low variance threshold                 0
18                 Normalize              True
19          Normalize method            zscore
20            Fold Generator             KFold
21               Fold Number                10
22                  CPU Jobs                -1
23                   Use GPU             False
24            Log Experiment             False
25           Experiment Name  reg-default-name
26                       USI              15ac
2022-09-26 23:41:47,931:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:41:47,931:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:41:48,126:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:41:48,126:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-26 23:41:48,166:INFO:setup() successfully completed in 16.8s...............
2022-09-26 23:42:09,057:INFO:Initializing compare_models()
2022-09-26 23:42:09,057:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-09-26 23:42:09,058:INFO:Checking exceptions
2022-09-26 23:42:09,071:INFO:Preparing display monitor
2022-09-26 23:42:09,171:INFO:Initializing Linear Regression
2022-09-26 23:42:09,171:INFO:Total runtime is 0.0 minutes
2022-09-26 23:42:09,185:INFO:SubProcess create_model() called ==================================
2022-09-26 23:42:09,185:INFO:Initializing create_model()
2022-09-26 23:42:09,185:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002EDA9D093D0>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:42:09,187:INFO:Checking exceptions
2022-09-26 23:42:09,202:INFO:Importing libraries
2022-09-26 23:42:09,203:INFO:Copying training dataset
2022-09-26 23:42:09,229:INFO:Defining folds
2022-09-26 23:42:09,232:INFO:Declaring metric variables
2022-09-26 23:42:09,242:INFO:Importing untrained model
2022-09-26 23:42:09,256:INFO:Linear Regression Imported successfully
2022-09-26 23:42:09,270:INFO:Starting cross validation
2022-09-26 23:42:09,292:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:42:11,825:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:42:11,825:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:42:11,825:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:42:11,890:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:42:11,922:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:42:11,946:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:42:11,978:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:42:12,043:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:42:14,621:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:42:14,710:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:42:14,807:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:42:15,010:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:42:15,107:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:42:15,170:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:42:15,172:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:42:15,228:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:42:16,198:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:42:16,278:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:42:16,318:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:42:16,640:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:42:16,669:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:42:16,758:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:42:16,769:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:42:16,828:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:42:17,439:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:42:17,794:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:42:17,846:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:42:17,919:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:42:18,658:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:18,675:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:18,732:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:18,797:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:18,814:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:18,916:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:18,985:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:19,057:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:19,484:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:19,540:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:19,698:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:19,701:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:19,801:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:19,809:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:19,829:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:19,907:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:20,296:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:20,501:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:20,737:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:20,745:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:20,840:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:20,875:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:21,128:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:21,478:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:21,671:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:27,539:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:42:27,557:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-09-26 23:42:30,133:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:30,143:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:31,909:INFO:Calculating mean and std
2022-09-26 23:42:31,917:INFO:Creating metrics dataframe
2022-09-26 23:42:31,941:INFO:Uploading results into container
2022-09-26 23:42:31,943:INFO:Uploading model into container now
2022-09-26 23:42:31,943:INFO:master_model_container: 1
2022-09-26 23:42:31,943:INFO:display_container: 2
2022-09-26 23:42:31,949:INFO:LinearRegression(n_jobs=-1)
2022-09-26 23:42:31,949:INFO:create_model() successfully completed......................................
2022-09-26 23:42:32,456:INFO:SubProcess create_model() end ==================================
2022-09-26 23:42:32,456:INFO:Creating metrics dataframe
2022-09-26 23:42:32,491:INFO:Initializing Lasso Regression
2022-09-26 23:42:32,494:INFO:Total runtime is 0.38872867027918495 minutes
2022-09-26 23:42:32,507:INFO:SubProcess create_model() called ==================================
2022-09-26 23:42:32,508:INFO:Initializing create_model()
2022-09-26 23:42:32,508:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002EDA9D093D0>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:42:32,508:INFO:Checking exceptions
2022-09-26 23:42:32,519:INFO:Importing libraries
2022-09-26 23:42:32,519:INFO:Copying training dataset
2022-09-26 23:42:32,551:INFO:Defining folds
2022-09-26 23:42:32,551:INFO:Declaring metric variables
2022-09-26 23:42:32,564:INFO:Importing untrained model
2022-09-26 23:42:32,586:INFO:Lasso Regression Imported successfully
2022-09-26 23:42:32,610:INFO:Starting cross validation
2022-09-26 23:42:32,626:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:42:34,686:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.582e+10, tolerance: 6.295e+08
  model = cd_fast.enet_coordinate_descent(

2022-09-26 23:42:34,826:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.580e+10, tolerance: 5.928e+08
  model = cd_fast.enet_coordinate_descent(

2022-09-26 23:42:34,933:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.032e+11, tolerance: 6.165e+08
  model = cd_fast.enet_coordinate_descent(

2022-09-26 23:42:35,035:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.223e+09, tolerance: 6.002e+08
  model = cd_fast.enet_coordinate_descent(

2022-09-26 23:42:35,101:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.325e+10, tolerance: 5.782e+08
  model = cd_fast.enet_coordinate_descent(

2022-09-26 23:42:35,207:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.418e+09, tolerance: 6.209e+08
  model = cd_fast.enet_coordinate_descent(

2022-09-26 23:42:35,254:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.094e+10, tolerance: 6.162e+08
  model = cd_fast.enet_coordinate_descent(

2022-09-26 23:42:35,305:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+10, tolerance: 5.933e+08
  model = cd_fast.enet_coordinate_descent(

2022-09-26 23:42:36,595:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:36,625:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:36,771:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:36,771:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:36,907:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:36,933:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:36,949:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:37,080:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:37,551:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:37,589:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:37,611:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:37,718:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:246: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_transform(transformer, X)

2022-09-26 23:42:39,071:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.657e+10, tolerance: 6.387e+08
  model = cd_fast.enet_coordinate_descent(

2022-09-26 23:42:39,186:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.567e+10, tolerance: 5.818e+08
  model = cd_fast.enet_coordinate_descent(

2022-09-26 23:42:40,942:INFO:Calculating mean and std
2022-09-26 23:42:40,950:INFO:Creating metrics dataframe
2022-09-26 23:42:40,958:INFO:Uploading results into container
2022-09-26 23:42:40,958:INFO:Uploading model into container now
2022-09-26 23:42:40,958:INFO:master_model_container: 2
2022-09-26 23:42:40,958:INFO:display_container: 2
2022-09-26 23:42:40,958:INFO:Lasso(random_state=2156)
2022-09-26 23:42:40,958:INFO:create_model() successfully completed......................................
2022-09-26 23:42:41,255:INFO:SubProcess create_model() end ==================================
2022-09-26 23:42:41,255:INFO:Creating metrics dataframe
2022-09-26 23:42:41,296:INFO:Initializing Ridge Regression
2022-09-26 23:42:41,296:INFO:Total runtime is 0.5354161540667216 minutes
2022-09-26 23:42:41,321:INFO:SubProcess create_model() called ==================================
2022-09-26 23:42:41,322:INFO:Initializing create_model()
2022-09-26 23:42:41,323:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002EDA9D093D0>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:42:41,323:INFO:Checking exceptions
2022-09-26 23:42:41,342:INFO:Importing libraries
2022-09-26 23:42:41,343:INFO:Copying training dataset
2022-09-26 23:42:41,376:INFO:Defining folds
2022-09-26 23:42:41,376:INFO:Declaring metric variables
2022-09-26 23:42:41,392:INFO:Importing untrained model
2022-09-26 23:42:41,408:INFO:Ridge Regression Imported successfully
2022-09-26 23:42:41,424:INFO:Starting cross validation
2022-09-26 23:42:41,440:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:42:44,724:INFO:Calculating mean and std
2022-09-26 23:42:44,727:INFO:Creating metrics dataframe
2022-09-26 23:42:44,745:INFO:Uploading results into container
2022-09-26 23:42:44,749:INFO:Uploading model into container now
2022-09-26 23:42:44,752:INFO:master_model_container: 3
2022-09-26 23:42:44,752:INFO:display_container: 2
2022-09-26 23:42:44,752:INFO:Ridge(random_state=2156)
2022-09-26 23:42:44,752:INFO:create_model() successfully completed......................................
2022-09-26 23:42:45,195:INFO:SubProcess create_model() end ==================================
2022-09-26 23:42:45,195:INFO:Creating metrics dataframe
2022-09-26 23:42:45,233:INFO:Initializing Elastic Net
2022-09-26 23:42:45,233:INFO:Total runtime is 0.6010315736134847 minutes
2022-09-26 23:42:45,241:INFO:SubProcess create_model() called ==================================
2022-09-26 23:42:45,249:INFO:Initializing create_model()
2022-09-26 23:42:45,249:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002EDA9D093D0>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:42:45,249:INFO:Checking exceptions
2022-09-26 23:42:45,257:INFO:Importing libraries
2022-09-26 23:42:45,257:INFO:Copying training dataset
2022-09-26 23:42:45,285:INFO:Defining folds
2022-09-26 23:42:45,285:INFO:Declaring metric variables
2022-09-26 23:42:45,298:INFO:Importing untrained model
2022-09-26 23:42:45,305:INFO:Elastic Net Imported successfully
2022-09-26 23:42:45,329:INFO:Starting cross validation
2022-09-26 23:42:45,335:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:42:49,118:INFO:Calculating mean and std
2022-09-26 23:42:49,131:INFO:Creating metrics dataframe
2022-09-26 23:42:49,145:INFO:Uploading results into container
2022-09-26 23:42:49,147:INFO:Uploading model into container now
2022-09-26 23:42:49,147:INFO:master_model_container: 4
2022-09-26 23:42:49,147:INFO:display_container: 2
2022-09-26 23:42:49,147:INFO:ElasticNet(random_state=2156)
2022-09-26 23:42:49,154:INFO:create_model() successfully completed......................................
2022-09-26 23:42:49,606:INFO:SubProcess create_model() end ==================================
2022-09-26 23:42:49,607:INFO:Creating metrics dataframe
2022-09-26 23:42:49,665:INFO:Initializing Least Angle Regression
2022-09-26 23:42:49,665:INFO:Total runtime is 0.6749061226844788 minutes
2022-09-26 23:42:49,684:INFO:SubProcess create_model() called ==================================
2022-09-26 23:42:49,687:INFO:Initializing create_model()
2022-09-26 23:42:49,687:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002EDA9D093D0>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:42:49,687:INFO:Checking exceptions
2022-09-26 23:42:49,715:INFO:Importing libraries
2022-09-26 23:42:49,715:INFO:Copying training dataset
2022-09-26 23:42:49,764:INFO:Defining folds
2022-09-26 23:42:49,764:INFO:Declaring metric variables
2022-09-26 23:42:49,782:INFO:Importing untrained model
2022-09-26 23:42:49,810:INFO:Least Angle Regression Imported successfully
2022-09-26 23:42:49,845:INFO:Starting cross validation
2022-09-26 23:42:49,877:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:42:51,347:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:42:51,404:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:42:51,436:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=4.037e+01, with an active set of 64 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,444:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=3.163e+01, with an active set of 71 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,452:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=4.520e+03, with an active set of 74 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,452:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=1.705e+03, with an active set of 74 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,452:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=1.382e+03, with an active set of 74 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,457:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=1.258e+03, with an active set of 77 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,457:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=5.327e+01, with an active set of 53 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,461:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=1.318e+03, with an active set of 79 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,461:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:42:51,461:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=5.065e+01, with an active set of 57 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,469:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=1.101e+03, with an active set of 86 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,469:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=3.988e+01, with an active set of 64 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,470:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=1.061e+03, with an active set of 87 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,470:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=3.816e+01, with an active set of 65 regressors, and the smallest cholesky pivot element being 9.306e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,470:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=1.053e+03, with an active set of 87 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,470:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=1.036e+03, with an active set of 88 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,470:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=9.995e+02, with an active set of 88 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,474:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=3.509e+01, with an active set of 68 regressors, and the smallest cholesky pivot element being 9.306e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,477:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=9.220e+02, with an active set of 92 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,477:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 82 iterations, i.e. alpha=3.173e+01, with an active set of 75 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,477:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 82 iterations, i.e. alpha=3.030e+01, with an active set of 75 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,477:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=8.342e+02, with an active set of 97 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,484:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 127 iterations, i.e. alpha=7.109e+02, with an active set of 100 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,484:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 127 iterations, i.e. alpha=6.985e+02, with an active set of 100 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,484:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 127 iterations, i.e. alpha=6.598e+02, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,484:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=6.420e+02, with an active set of 101 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,484:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 130 iterations, i.e. alpha=6.244e+02, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,491:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=2.831e+01, with an active set of 85 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,491:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=6.170e+02, with an active set of 105 regressors, and the smallest cholesky pivot element being 9.714e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,492:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=6.163e+02, with an active set of 105 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,492:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:42:51,492:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 138 iterations, i.e. alpha=6.048e+02, with an active set of 108 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,492:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=2.831e+01, with an active set of 91 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,492:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 138 iterations, i.e. alpha=5.921e+02, with an active set of 108 regressors, and the smallest cholesky pivot element being 9.599e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,492:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 138 iterations, i.e. alpha=5.562e+02, with an active set of 108 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,500:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=5.488e+02, with an active set of 111 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,500:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=4.878e+02, with an active set of 111 regressors, and the smallest cholesky pivot element being 9.599e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,500:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=4.703e+02, with an active set of 111 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,500:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=4.478e+02, with an active set of 111 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,500:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=3.854e+02, with an active set of 111 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,500:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=3.558e+01, with an active set of 95 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,500:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=5.487e+01, with an active set of 51 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,509:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 150 iterations, i.e. alpha=3.712e+02, with an active set of 115 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,509:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 150 iterations, i.e. alpha=3.693e+02, with an active set of 115 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,509:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=3.121e+01, with an active set of 101 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,509:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=5.033e+01, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,509:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 119 iterations, i.e. alpha=2.851e+01, with an active set of 102 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,509:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=2.941e+02, with an active set of 117 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,509:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 119 iterations, i.e. alpha=2.763e+01, with an active set of 102 regressors, and the smallest cholesky pivot element being 8.093e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,509:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=2.927e+02, with an active set of 117 regressors, and the smallest cholesky pivot element being 9.483e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,509:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=2.500e+02, with an active set of 117 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,509:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=4.487e+01, with an active set of 60 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,509:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=2.422e+01, with an active set of 105 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,509:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=2.829e+02, with an active set of 120 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,509:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=2.157e+02, with an active set of 120 regressors, and the smallest cholesky pivot element being 9.483e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,517:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=2.027e+02, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,517:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=2.296e+01, with an active set of 106 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,517:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=1.910e+02, with an active set of 120 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,517:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=2.242e+01, with an active set of 106 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,517:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=1.888e+02, with an active set of 120 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,517:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=2.087e+01, with an active set of 108 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,517:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 158 iterations, i.e. alpha=2.854e+02, with an active set of 121 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,517:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=1.985e+01, with an active set of 108 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,517:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 158 iterations, i.e. alpha=1.704e+02, with an active set of 121 regressors, and the smallest cholesky pivot element being 9.483e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,517:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=1.928e+01, with an active set of 108 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,517:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 158 iterations, i.e. alpha=1.365e+02, with an active set of 121 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,517:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 158 iterations, i.e. alpha=1.218e+02, with an active set of 121 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,517:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=3.360e+01, with an active set of 69 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,517:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=1.707e+01, with an active set of 109 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,517:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=1.600e+01, with an active set of 109 regressors, and the smallest cholesky pivot element being 8.093e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,525:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 127 iterations, i.e. alpha=1.583e+01, with an active set of 110 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,517:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 158 iterations, i.e. alpha=1.207e+02, with an active set of 121 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,525:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 158 iterations, i.e. alpha=1.163e+02, with an active set of 121 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,525:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=1.468e+01, with an active set of 111 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,525:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 158 iterations, i.e. alpha=1.138e+02, with an active set of 121 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,525:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 158 iterations, i.e. alpha=1.112e+02, with an active set of 121 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,525:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=3.344e+01, with an active set of 69 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,525:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=1.483e+01, with an active set of 114 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,525:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 158 iterations, i.e. alpha=8.526e+01, with an active set of 121 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,525:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=1.274e+01, with an active set of 114 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,533:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=7.438e+01, with an active set of 123 regressors, and the smallest cholesky pivot element being 9.483e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,533:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 82 iterations, i.e. alpha=2.936e+01, with an active set of 74 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,533:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=7.252e+01, with an active set of 123 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,533:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=6.598e+01, with an active set of 123 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,533:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=1.245e+01, with an active set of 116 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,533:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=5.727e+01, with an active set of 123 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,533:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=5.725e+01, with an active set of 123 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,533:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=4.585e+01, with an active set of 123 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,533:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 136 iterations, i.e. alpha=1.188e+01, with an active set of 117 regressors, and the smallest cholesky pivot element being 8.093e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,533:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=2.712e+01, with an active set of 77 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,533:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=4.135e+01, with an active set of 123 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,533:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=3.673e+01, with an active set of 123 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,533:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=2.681e+01, with an active set of 123 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,533:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 138 iterations, i.e. alpha=1.686e+01, with an active set of 118 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,533:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=1.981e+01, with an active set of 123 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,533:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=1.280e+01, with an active set of 123 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,541:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 139 iterations, i.e. alpha=1.062e+01, with an active set of 119 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,541:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=6.066e+00, with an active set of 123 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,541:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 140 iterations, i.e. alpha=1.033e+01, with an active set of 120 regressors, and the smallest cholesky pivot element being 9.884e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,541:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=4.861e+00, with an active set of 124 regressors, and the smallest cholesky pivot element being 9.483e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,541:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 140 iterations, i.e. alpha=1.016e+01, with an active set of 120 regressors, and the smallest cholesky pivot element being 8.093e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,541:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 140 iterations, i.e. alpha=1.016e+01, with an active set of 120 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,541:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=4.166e+00, with an active set of 124 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,541:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 140 iterations, i.e. alpha=9.435e+00, with an active set of 120 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,541:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=3.914e+00, with an active set of 124 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

el = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:42:51,541:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 140 iterations, i.e. alpha=8.856e+00, with an active set of 120 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,541:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=2.392e+01, with an active set of 87 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,541:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=2.020e+00, with an active set of 124 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,541:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.990e+00, with an active set of 124 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,541:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 140 iterations, i.e. alpha=8.414e+00, with an active set of 120 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,541:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.515e+00, with an active set of 124 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,541:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 140 iterations, i.e. alpha=7.103e+00, with an active set of 120 regressors, and the smallest cholesky pivot element being 7.671e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,541:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.431e+00, with an active set of 124 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,541:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 140 iterations, i.e. alpha=6.731e+00, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,541:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.347e+00, with an active set of 124 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,541:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=2.332e+01, with an active set of 89 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,549:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.262e+00, with an active set of 124 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,549:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=9.258e-01, with an active set of 124 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,549:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=6.726e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 9.884e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,549:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=8.837e-01, with an active set of 124 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,549:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=5.549e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,549:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=3.472e-01, with an active set of 124 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,549:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=4.891e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,549:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.262e-01, with an active set of 124 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,549:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=4.654e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,549:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=7.890e-02, with an active set of 124 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,549:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=3.868e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,549:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=3.803e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,549:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 105 iterations, i.e. alpha=2.216e+01, with an active set of 95 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,549:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=3.318e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 8.093e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,549:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 105 iterations, i.e. alpha=2.096e+01, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,549:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=3.165e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,549:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=3.117e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,549:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=2.919e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,557:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=2.899e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,557:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=2.023e+01, with an active set of 97 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,557:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=2.574e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,557:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=2.451e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,557:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=2.302e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 7.671e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,557:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=2.151e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,557:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=1.935e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,557:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=1.151e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,557:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=9.113e-01, with an active set of 121 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,557:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=6.421e-01, with an active set of 121 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,557:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=4.245e-01, with an active set of 121 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,557:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=2.994e+01, with an active set of 101 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,557:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=3.538e-01, with an active set of 121 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,557:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=8.872e-02, with an active set of 121 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,565:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=4.885e+01, with an active set of 106 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,565:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=4.164e+01, with an active set of 106 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,565:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=3.732e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,565:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=4.123e+01, with an active set of 106 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,565:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=3.409e+01, with an active set of 106 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,565:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=3.118e+01, with an active set of 106 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,565:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:42:51,565:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=2.893e+01, with an active set of 108 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,565:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 82 iterations, i.e. alpha=3.635e+01, with an active set of 79 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,573:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 127 iterations, i.e. alpha=2.594e+01, with an active set of 109 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,573:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=2.527e+01, with an active set of 112 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,573:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=2.461e+01, with an active set of 112 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,573:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=2.966e+01, with an active set of 85 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,581:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=7.528e+01, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,585:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=2.804e+01, with an active set of 90 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,585:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 137 iterations, i.e. alpha=2.542e+01, with an active set of 113 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,585:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 137 iterations, i.e. alpha=2.519e+01, with an active set of 113 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,585:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=2.788e+01, with an active set of 92 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,585:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=2.667e+01, with an active set of 92 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,590:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 138 iterations, i.e. alpha=2.429e+01, with an active set of 114 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,590:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 99 iterations, i.e. alpha=2.411e+01, with an active set of 96 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,590:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=7.132e+01, with an active set of 49 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,590:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 140 iterations, i.e. alpha=2.367e+01, with an active set of 116 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,590:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=2.222e+01, with an active set of 97 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,590:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 140 iterations, i.e. alpha=2.365e+01, with an active set of 116 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,590:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 140 iterations, i.e. alpha=2.224e+01, with an active set of 116 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,597:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=6.488e+01, with an active set of 53 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,597:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=1.552e+01, with an active set of 100 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,597:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=1.496e+01, with an active set of 100 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,597:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 143 iterations, i.e. alpha=2.279e+01, with an active set of 118 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,597:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 143 iterations, i.e. alpha=2.175e+01, with an active set of 118 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,597:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 143 iterations, i.e. alpha=1.904e+01, with an active set of 118 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,597:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 143 iterations, i.e. alpha=1.804e+01, with an active set of 118 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,597:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 105 iterations, i.e. alpha=1.431e+01, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,597:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=9.014e+01, with an active set of 55 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,597:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 143 iterations, i.e. alpha=1.742e+01, with an active set of 118 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,597:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 105 iterations, i.e. alpha=1.352e+01, with an active set of 102 regressors, and the smallest cholesky pivot element being 7.885e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,597:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 143 iterations, i.e. alpha=1.629e+01, with an active set of 118 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,597:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 143 iterations, i.e. alpha=1.416e+01, with an active set of 118 regressors, and the smallest cholesky pivot element being 7.068e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,597:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=1.336e+01, with an active set of 103 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,597:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 143 iterations, i.e. alpha=1.073e+01, with an active set of 118 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,597:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 143 iterations, i.e. alpha=8.988e+00, with an active set of 118 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,597:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 143 iterations, i.e. alpha=8.634e+00, with an active set of 118 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,597:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 143 iterations, i.e. alpha=8.323e+00, with an active set of 118 regressors, and the smallest cholesky pivot element being 8.363e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,597:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=6.017e+01, with an active set of 59 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,597:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=1.223e+01, with an active set of 105 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,597:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 143 iterations, i.e. alpha=8.147e+00, with an active set of 118 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,605:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=1.209e+01, with an active set of 105 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,605:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 143 iterations, i.e. alpha=7.279e+00, with an active set of 118 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,605:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=5.658e+01, with an active set of 61 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,608:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 144 iterations, i.e. alpha=6.635e+00, with an active set of 119 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,608:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 144 iterations, i.e. alpha=6.556e+00, with an active set of 119 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,608:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 144 iterations, i.e. alpha=3.977e+00, with an active set of 119 regressors, and the smallest cholesky pivot element being 8.363e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,610:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 144 iterations, i.e. alpha=2.782e+00, with an active set of 119 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,610:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.093e+01, with an active set of 108 regressors, and the smallest cholesky pivot element being 9.541e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,610:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 145 iterations, i.e. alpha=2.542e+00, with an active set of 120 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,610:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.080e+01, with an active set of 108 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,610:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=5.031e+01, with an active set of 67 regressors, and the smallest cholesky pivot element being 9.940e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,612:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.054e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,612:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=1.029e+01, with an active set of 109 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,612:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.020e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,613:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=9.923e+00, with an active set of 109 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,613:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=1.833e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,613:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=4.753e+01, with an active set of 68 regressors, and the smallest cholesky pivot element being 9.940e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(


2022-09-26 23:42:51,613:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=1.573e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,613:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=1.467e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,613:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=6.302e+01, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,613:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=1.461e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,613:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=1.207e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,613:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 119 iterations, i.e. alpha=8.140e+00, with an active set of 111 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,613:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=1.142e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,613:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=1.121e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,613:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=1.065e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,613:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=8.359e-01, with an active set of 121 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,613:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=6.938e+00, with an active set of 113 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,613:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=6.864e+00, with an active set of 113 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,613:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=4.338e-01, with an active set of 121 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,613:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=6.468e+00, with an active set of 113 regressors, and the smallest cholesky pivot element being 7.885e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,621:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.220e-01, with an active set of 121 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,621:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=6.410e+00, with an active set of 113 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,621:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.194e-01, with an active set of 121 regressors, and the smallest cholesky pivot element being 7.068e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,621:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=6.313e+00, with an active set of 113 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,621:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=4.412e+01, with an active set of 75 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,621:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=1.403e-01, with an active set of 121 regressors, and the smallest cholesky pivot element being 8.363e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,621:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=5.868e+00, with an active set of 113 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,623:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=4.706e+01, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,623:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=6.165e-02, with an active set of 121 regressors, and the smallest cholesky pivot element being 8.363e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,623:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.361e-02, with an active set of 121 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,623:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.184e-02, with an active set of 121 regressors, and the smallest cholesky pivot element being 8.363e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,623:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=5.724e+00, with an active set of 114 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,623:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.103e-02, with an active set of 121 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,623:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=5.230e+00, with an active set of 115 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,623:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=4.876e+00, with an active set of 115 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,623:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=4.589e+00, with an active set of 115 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,623:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=3.242e+00, with an active set of 116 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,630:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=4.324e+01, with an active set of 60 regressors, and the smallest cholesky pivot element being 7.885e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,630:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=2.886e+00, with an active set of 116 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,630:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=2.627e+00, with an active set of 116 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,630:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=4.230e+01, with an active set of 61 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,630:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=2.323e+00, with an active set of 118 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,630:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=1.818e+00, with an active set of 118 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,630:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=1.817e+00, with an active set of 118 regressors, and the smallest cholesky pivot element being 9.541e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,630:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=1.784e+00, with an active set of 118 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,630:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=3.686e+01, with an active set of 65 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,630:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=1.637e+00, with an active set of 118 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,630:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=1.548e+00, with an active set of 118 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,630:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=1.427e+00, with an active set of 118 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,638:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=1.249e+00, with an active set of 118 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,638:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=3.302e+01, with an active set of 67 regressors, and the smallest cholesky pivot element being 7.814e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,638:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 127 iterations, i.e. alpha=9.635e-01, with an active set of 119 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,638:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=3.238e+01, with an active set of 67 regressors, and the smallest cholesky pivot element being 7.814e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,638:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=7.728e-01, with an active set of 120 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,638:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=6.662e-01, with an active set of 120 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,638:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=3.084e+01, with an active set of 68 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,638:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=6.522e-01, with an active set of 120 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,638:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=5.507e-01, with an active set of 120 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,638:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=5.063e-01, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,638:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=2.849e+01, with an active set of 70 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,638:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=4.589e-01, with an active set of 120 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,638:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=4.373e-01, with an active set of 120 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,646:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=4.219e-01, with an active set of 120 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,646:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.856e-01, with an active set of 120 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,646:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=2.908e+01, with an active set of 72 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,646:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.507e-01, with an active set of 120 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,646:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=2.791e+01, with an active set of 72 regressors, and the smallest cholesky pivot element being 7.814e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,646:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.313e-01, with an active set of 120 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,646:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:42:51,646:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=1.923e-01, with an active set of 120 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,646:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=1.352e-01, with an active set of 120 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,646:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=1.222e-01, with an active set of 120 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,646:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=9.600e-02, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,646:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=2.590e+01, with an active set of 74 regressors, and the smallest cholesky pivot element being 7.814e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,646:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=8.520e-02, with an active set of 120 regressors, and the smallest cholesky pivot element being 9.541e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,646:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=7.484e-02, with an active set of 120 regressors, and the smallest cholesky pivot element being 7.885e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,646:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=7.366e-02, with an active set of 120 regressors, and the smallest cholesky pivot element being 9.657e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,646:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=2.332e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,646:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=6.094e-02, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,646:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=5.531e-02, with an active set of 120 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,646:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=4.462e-02, with an active set of 120 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,654:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=2.261e+01, with an active set of 78 regressors, and the smallest cholesky pivot element being 7.814e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,654:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=3.227e-03, with an active set of 121 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,654:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=2.211e+01, with an active set of 78 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,657:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=2.364e-03, with an active set of 121 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,657:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=1.466e-03, with an active set of 121 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,657:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=1.272e-03, with an active set of 121 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,657:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=1.187e-03, with an active set of 121 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,657:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=6.608e-04, with an active set of 121 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,657:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=5.668e-04, with an active set of 121 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,662:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=4.440e-04, with an active set of 121 regressors, and the smallest cholesky pivot element being 9.541e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,662:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=3.881e-04, with an active set of 121 regressors, and the smallest cholesky pivot element being 9.657e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,662:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=2.927e-04, with an active set of 121 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,662:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=2.828e-04, with an active set of 121 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,662:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=2.772e-04, with an active set of 121 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,662:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=2.525e-04, with an active set of 121 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,662:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=8.122e+01, with an active set of 82 regressors, and the smallest cholesky pivot element being 7.814e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(


2022-09-26 23:42:51,662:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=6.456e+01, with an active set of 82 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(


2022-09-26 23:42:51,662:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=1.312e-04, with an active set of 121 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,662:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=1.250e-04, with an active set of 121 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,662:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=5.470e-05, with an active set of 121 regressors, and the smallest cholesky pivot element being 7.885e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,662:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=5.284e-05, with an active set of 121 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,662:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:42:51,670:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=4.127e+01, with an active set of 86 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,670:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=3.648e+01, with an active set of 86 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,675:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=3.402e+01, with an active set of 87 regressors, and the smallest cholesky pivot element being 7.814e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,675:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=3.311e+01, with an active set of 87 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,686:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=4.260e+01, with an active set of 90 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,686:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=3.170e+01, with an active set of 90 regressors, and the smallest cholesky pivot element being 7.525e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,686:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=2.727e+01, with an active set of 90 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,686:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=2.684e+01, with an active set of 90 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,695:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=2.339e+01, with an active set of 96 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,695:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=2.062e+01, with an active set of 97 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,695:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=1.878e+01, with an active set of 98 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,698:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 191 iterations, i.e. alpha=6.452e+07, with an active set of 142 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,698:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=7.202e+01, with an active set of 101 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,698:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=4.431e+01, with an active set of 101 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,698:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=3.144e+01, with an active set of 101 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,705:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=8.715e+01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,712:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=8.613e+01, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,715:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=7.656e+01, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,715:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 147 iterations, i.e. alpha=3.752e+07, with an active set of 113 regressors, and the smallest cholesky pivot element being 9.828e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,720:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=6.216e+01, with an active set of 52 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,726:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=6.821e+07, with an active set of 121 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,728:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=6.710e+07, with an active set of 121 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,728:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=6.446e+07, with an active set of 121 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,728:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=5.675e+01, with an active set of 57 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,729:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 162 iterations, i.e. alpha=5.527e+07, with an active set of 122 regressors, and the smallest cholesky pivot element being 9.828e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,731:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 162 iterations, i.e. alpha=5.167e+07, with an active set of 122 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,732:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 162 iterations, i.e. alpha=4.633e+07, with an active set of 122 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,733:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 162 iterations, i.e. alpha=3.759e+07, with an active set of 122 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,734:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 163 iterations, i.e. alpha=3.710e+07, with an active set of 123 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,735:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 163 iterations, i.e. alpha=3.656e+07, with an active set of 123 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,735:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 163 iterations, i.e. alpha=3.264e+07, with an active set of 123 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,736:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 164 iterations, i.e. alpha=3.137e+07, with an active set of 124 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,737:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=3.230e+07, with an active set of 125 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,741:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=2.935e+07, with an active set of 125 regressors, and the smallest cholesky pivot element being 8.689e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,742:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=2.852e+07, with an active set of 125 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,743:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=2.646e+07, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,744:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=2.237e+07, with an active set of 126 regressors, and the smallest cholesky pivot element being 9.828e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,744:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.817e+07, with an active set of 126 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,744:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.544e+07, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,744:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.465e+07, with an active set of 126 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,744:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.452e+07, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,744:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.966e+01, with an active set of 73 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,744:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.392e+07, with an active set of 126 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,744:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.351e+07, with an active set of 126 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,744:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.260e+07, with an active set of 126 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,744:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=8.141e+06, with an active set of 126 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,744:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=6.066e+06, with an active set of 126 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,744:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=4.115e+06, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,744:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=2.141e+06, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,750:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.649e+06, with an active set of 126 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,750:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.194e+06, with an active set of 126 regressors, and the smallest cholesky pivot element being 8.689e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,750:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=7.171e+05, with an active set of 126 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,750:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=2.168e+05, with an active set of 126 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,750:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 87 iterations, i.e. alpha=4.568e+01, with an active set of 80 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,750:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 87 iterations, i.e. alpha=3.285e+01, with an active set of 80 regressors, and the smallest cholesky pivot element being 7.885e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,759:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 139 iterations, i.e. alpha=4.195e+04, with an active set of 113 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,759:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 139 iterations, i.e. alpha=4.002e+04, with an active set of 113 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,775:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 147 iterations, i.e. alpha=4.190e+04, with an active set of 120 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,775:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 147 iterations, i.e. alpha=3.677e+04, with an active set of 120 regressors, and the smallest cholesky pivot element being 8.816e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,775:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 148 iterations, i.e. alpha=3.308e+04, with an active set of 121 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,775:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 153 iterations, i.e. alpha=3.706e+04, with an active set of 124 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,775:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 153 iterations, i.e. alpha=3.048e+04, with an active set of 124 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,783:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=4.071e+01, with an active set of 105 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,783:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 153 iterations, i.e. alpha=2.860e+04, with an active set of 124 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,783:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=2.664e+04, with an active set of 125 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,785:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=2.473e+04, with an active set of 125 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,785:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=2.354e+04, with an active set of 125 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,785:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=2.255e+04, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,785:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=2.183e+04, with an active set of 126 regressors, and the smallest cholesky pivot element being 9.884e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,792:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.966e+05, with an active set of 131 regressors, and the smallest cholesky pivot element being 9.884e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,792:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.639e+05, with an active set of 131 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,792:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.520e+05, with an active set of 131 regressors, and the smallest cholesky pivot element being 8.689e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,792:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=9.678e+04, with an active set of 131 regressors, and the smallest cholesky pivot element being 8.689e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,792:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=8.970e+04, with an active set of 131 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,792:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=5.265e+04, with an active set of 131 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,792:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.871e+04, with an active set of 131 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,792:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.791e+04, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,792:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.511e+04, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,792:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.158e+04, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,799:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.497e+04, with an active set of 131 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,799:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.430e+04, with an active set of 131 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,799:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 133 iterations, i.e. alpha=7.470e+02, with an active set of 110 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,807:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 138 iterations, i.e. alpha=6.633e+02, with an active set of 115 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:51,807:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 138 iterations, i.e. alpha=6.404e+02, with an active set of 115 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,198:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:42:53,217:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:42:53,293:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=5.181e+01, with an active set of 62 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,311:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=2.741e+01, with an active set of 65 regressors, and the smallest cholesky pivot element being 9.365e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,313:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.592e+01, with an active set of 67 regressors, and the smallest cholesky pivot element being 9.365e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,313:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=2.998e+01, with an active set of 77 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,320:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=1.971e+01, with an active set of 77 regressors, and the smallest cholesky pivot element being 9.246e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,322:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=1.918e+01, with an active set of 80 regressors, and the smallest cholesky pivot element being 9.246e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,326:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=1.684e+01, with an active set of 81 regressors, and the smallest cholesky pivot element being 9.246e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,334:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=3.198e+01, with an active set of 91 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,334:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=1.240e+01, with an active set of 89 regressors, and the smallest cholesky pivot element being 9.246e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,334:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=1.135e+01, with an active set of 90 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,342:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=8.905e+00, with an active set of 95 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,344:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 119 iterations, i.e. alpha=3.807e+01, with an active set of 98 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,347:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 105 iterations, i.e. alpha=7.939e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,347:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=3.049e+01, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,347:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 105 iterations, i.e. alpha=7.687e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,347:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=2.975e+01, with an active set of 103 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,347:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=2.705e+01, with an active set of 103 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,347:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=8.450e+00, with an active set of 100 regressors, and the smallest cholesky pivot element being 9.246e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,347:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=7.041e+00, with an active set of 103 regressors, and the smallest cholesky pivot element being 9.246e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,347:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=7.006e+00, with an active set of 103 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,347:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=2.743e+01, with an active set of 108 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,347:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=6.852e+00, with an active set of 104 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,347:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=2.332e+01, with an active set of 108 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,347:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=6.852e+00, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,347:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=6.777e+00, with an active set of 104 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,357:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=2.443e+01, with an active set of 111 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,357:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=7.496e+00, with an active set of 106 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,357:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=2.219e+01, with an active set of 111 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,357:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=2.177e+01, with an active set of 111 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,357:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=5.546e+00, with an active set of 106 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,357:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=5.011e+00, with an active set of 108 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,357:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=4.887e+00, with an active set of 108 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,357:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 141 iterations, i.e. alpha=2.987e+01, with an active set of 115 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,357:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=6.813e+00, with an active set of 109 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,363:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=4.531e+00, with an active set of 109 regressors, and the smallest cholesky pivot element being 9.246e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,363:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=4.500e+00, with an active set of 109 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,364:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 143 iterations, i.e. alpha=3.005e+01, with an active set of 116 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,364:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 119 iterations, i.e. alpha=4.207e+00, with an active set of 110 regressors, and the smallest cholesky pivot element being 8.093e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,364:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 144 iterations, i.e. alpha=2.753e+01, with an active set of 117 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,364:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 119 iterations, i.e. alpha=4.083e+00, with an active set of 110 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,364:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 144 iterations, i.e. alpha=2.715e+01, with an active set of 117 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,364:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 144 iterations, i.e. alpha=2.506e+01, with an active set of 117 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,364:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=4.030e+00, with an active set of 112 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,364:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=3.862e+00, with an active set of 112 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,364:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 147 iterations, i.e. alpha=2.291e+01, with an active set of 119 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,364:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=3.715e+00, with an active set of 113 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,364:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 147 iterations, i.e. alpha=2.210e+01, with an active set of 119 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,364:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=3.320e+00, with an active set of 113 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,364:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 147 iterations, i.e. alpha=2.061e+01, with an active set of 119 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,364:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=3.099e+00, with an active set of 113 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,364:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 147 iterations, i.e. alpha=1.510e+01, with an active set of 119 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,364:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=2.949e+00, with an active set of 113 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,364:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 147 iterations, i.e. alpha=1.441e+01, with an active set of 119 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,364:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=2.519e+00, with an active set of 113 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,364:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 147 iterations, i.e. alpha=1.414e+01, with an active set of 119 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,364:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 147 iterations, i.e. alpha=1.350e+01, with an active set of 119 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,364:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 147 iterations, i.e. alpha=1.066e+01, with an active set of 119 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,364:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 147 iterations, i.e. alpha=9.448e+00, with an active set of 119 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,364:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=2.379e+00, with an active set of 114 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,371:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 148 iterations, i.e. alpha=8.984e+00, with an active set of 120 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,372:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 148 iterations, i.e. alpha=8.763e+00, with an active set of 120 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,372:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 148 iterations, i.e. alpha=7.258e+00, with an active set of 120 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,374:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=3.306e+00, with an active set of 116 regressors, and the smallest cholesky pivot element being 9.246e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,374:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 149 iterations, i.e. alpha=6.960e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,374:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 149 iterations, i.e. alpha=6.725e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,376:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 149 iterations, i.e. alpha=5.277e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,376:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 130 iterations, i.e. alpha=2.850e+00, with an active set of 117 regressors, and the smallest cholesky pivot element being 9.306e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,376:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 149 iterations, i.e. alpha=5.185e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,378:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 130 iterations, i.e. alpha=2.734e+00, with an active set of 117 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,378:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 130 iterations, i.e. alpha=2.206e+00, with an active set of 117 regressors, and the smallest cholesky pivot element being 9.483e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,379:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=4.475e+00, with an active set of 122 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,379:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=2.182e+00, with an active set of 118 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,379:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=3.855e+00, with an active set of 122 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,379:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=2.066e+00, with an active set of 118 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,379:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=3.747e+00, with an active set of 122 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,379:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=3.162e+00, with an active set of 122 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,379:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=1.689e+00, with an active set of 122 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,379:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 133 iterations, i.e. alpha=1.498e+00, with an active set of 119 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,379:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 133 iterations, i.e. alpha=1.402e+00, with an active set of 119 regressors, and the smallest cholesky pivot element being 9.483e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,379:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=1.093e+00, with an active set of 122 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,379:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 133 iterations, i.e. alpha=1.357e+00, with an active set of 119 regressors, and the smallest cholesky pivot element being 9.306e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,386:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 133 iterations, i.e. alpha=1.349e+00, with an active set of 119 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,386:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=9.983e-01, with an active set of 123 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,386:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 133 iterations, i.e. alpha=1.123e+00, with an active set of 119 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,386:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=7.853e-01, with an active set of 123 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,386:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 133 iterations, i.e. alpha=8.694e-01, with an active set of 119 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,386:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=6.694e-01, with an active set of 123 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,386:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 133 iterations, i.e. alpha=7.569e-01, with an active set of 119 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,388:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=5.613e-01, with an active set of 123 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,388:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 133 iterations, i.e. alpha=7.386e-01, with an active set of 119 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,388:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=5.089e-01, with an active set of 123 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,388:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 133 iterations, i.e. alpha=5.987e-01, with an active set of 119 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,389:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=4.048e-01, with an active set of 123 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,389:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 133 iterations, i.e. alpha=5.964e-01, with an active set of 119 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,389:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=1.853e-01, with an active set of 123 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,389:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 133 iterations, i.e. alpha=5.447e-01, with an active set of 119 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,389:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=1.662e-01, with an active set of 123 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,390:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 133 iterations, i.e. alpha=3.715e-01, with an active set of 119 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,390:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=1.518e-01, with an active set of 123 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,391:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 133 iterations, i.e. alpha=3.641e-01, with an active set of 119 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,391:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=1.503e-01, with an active set of 123 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,391:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 133 iterations, i.e. alpha=3.461e-01, with an active set of 119 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,391:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=1.344e-01, with an active set of 123 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,391:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 133 iterations, i.e. alpha=3.434e-01, with an active set of 119 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,391:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=1.101e-01, with an active set of 123 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,391:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 133 iterations, i.e. alpha=3.276e-01, with an active set of 119 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,391:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=7.720e-02, with an active set of 123 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,391:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 133 iterations, i.e. alpha=2.597e-01, with an active set of 119 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,391:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=6.795e-02, with an active set of 123 regressors, and the smallest cholesky pivot element being 7.224e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,391:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 133 iterations, i.e. alpha=2.597e-01, with an active set of 119 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,391:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=3.892e-02, with an active set of 123 regressors, and the smallest cholesky pivot element being 7.224e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,391:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 133 iterations, i.e. alpha=2.089e-01, with an active set of 119 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,393:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=2.641e-02, with an active set of 123 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,393:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 133 iterations, i.e. alpha=1.969e-01, with an active set of 119 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,393:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=2.246e-02, with an active set of 123 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,393:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 133 iterations, i.e. alpha=9.224e-02, with an active set of 119 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,393:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=1.706e-02, with an active set of 123 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,393:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 133 iterations, i.e. alpha=4.380e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:53,393:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=3.961e-03, with an active set of 123 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:54,003:INFO:Calculating mean and std
2022-09-26 23:42:54,012:INFO:Creating metrics dataframe
2022-09-26 23:42:54,035:INFO:Uploading results into container
2022-09-26 23:42:54,038:INFO:Uploading model into container now
2022-09-26 23:42:54,038:INFO:master_model_container: 5
2022-09-26 23:42:54,038:INFO:display_container: 2
2022-09-26 23:42:54,045:INFO:Lars(random_state=2156)
2022-09-26 23:42:54,045:INFO:create_model() successfully completed......................................
2022-09-26 23:42:54,515:INFO:SubProcess create_model() end ==================================
2022-09-26 23:42:54,515:INFO:Creating metrics dataframe
2022-09-26 23:42:54,568:INFO:Initializing Lasso Least Angle Regression
2022-09-26 23:42:54,574:INFO:Total runtime is 0.7567267775535584 minutes
2022-09-26 23:42:54,595:INFO:SubProcess create_model() called ==================================
2022-09-26 23:42:54,595:INFO:Initializing create_model()
2022-09-26 23:42:54,595:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002EDA9D093D0>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:42:54,595:INFO:Checking exceptions
2022-09-26 23:42:54,610:INFO:Importing libraries
2022-09-26 23:42:54,618:INFO:Copying training dataset
2022-09-26 23:42:54,669:INFO:Defining folds
2022-09-26 23:42:54,672:INFO:Declaring metric variables
2022-09-26 23:42:54,703:INFO:Importing untrained model
2022-09-26 23:42:54,728:INFO:Lasso Least Angle Regression Imported successfully
2022-09-26 23:42:54,823:INFO:Starting cross validation
2022-09-26 23:42:54,833:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:42:56,355:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-26 23:42:56,380:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-26 23:42:56,380:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-26 23:42:56,412:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-26 23:42:56,436:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=2.366e+01, with an active set of 64 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:56,452:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=1.183e+01, with an active set of 89 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:56,452:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=1.183e+01, with an active set of 89 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:56,462:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=1.045e+01, with an active set of 92 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:56,462:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=1.017e+01, with an active set of 93 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:56,469:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=6.551e+00, with an active set of 101 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:56,469:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=5.772e+00, with an active set of 106 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:56,469:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=5.608e+00, with an active set of 106 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:56,469:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=5.395e+00, with an active set of 106 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:56,469:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=6.134e+00, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:56,477:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=4.737e+00, with an active set of 107 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:56,477:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=4.737e+00, with an active set of 107 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:56,477:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 113 iterations, alpha=6.125e+00, previous alpha=6.109e+00, with an active set of 104 regressors.
  warnings.warn(

2022-09-26 23:42:56,477:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=4.475e+00, with an active set of 107 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:56,477:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 119 iterations, i.e. alpha=4.121e+00, with an active set of 109 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:56,477:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 120 iterations, alpha=4.971e+00, previous alpha=4.101e+00, with an active set of 109 regressors.
  warnings.warn(

2022-09-26 23:42:56,485:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=2.050e+01, with an active set of 69 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:56,494:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=1.594e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:56,509:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=1.025e+01, with an active set of 90 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:56,509:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 109 iterations, alpha=7.661e+00, previous alpha=7.512e+00, with an active set of 96 regressors.
  warnings.warn(

2022-09-26 23:42:56,735:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-26 23:42:56,743:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-26 23:42:56,759:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-26 23:42:56,767:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-26 23:42:56,807:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=2.670e+01, with an active set of 67 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:56,807:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=2.226e+01, with an active set of 64 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:56,807:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=2.542e+01, with an active set of 69 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:56,815:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=1.949e+01, with an active set of 77 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:56,823:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=1.329e+01, with an active set of 85 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:56,823:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=2.475e+01, with an active set of 64 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:56,823:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 97 iterations, alpha=1.281e+01, previous alpha=1.213e+01, with an active set of 88 regressors.
  warnings.warn(

2022-09-26 23:42:56,831:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=1.113e+01, with an active set of 86 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:56,840:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 82 iterations, i.e. alpha=2.235e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:56,840:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 110 iterations, alpha=7.278e+00, previous alpha=7.169e+00, with an active set of 97 regressors.
  warnings.warn(

2022-09-26 23:42:56,840:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=2.147e+01, with an active set of 79 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:56,856:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=1.238e+01, with an active set of 90 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:56,856:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 97 iterations, alpha=1.456e+01, previous alpha=1.435e+01, with an active set of 90 regressors.
  warnings.warn(

2022-09-26 23:42:56,856:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=9.417e+00, with an active set of 94 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:56,856:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 105 iterations, alpha=9.635e+00, previous alpha=9.283e+00, with an active set of 94 regressors.
  warnings.warn(

2022-09-26 23:42:58,259:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-26 23:42:58,286:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-26 23:42:58,358:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=3.781e+01, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:58,368:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=2.264e+01, with an active set of 64 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:58,374:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=1.796e+01, with an active set of 75 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:58,394:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=2.324e+01, with an active set of 70 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:58,415:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 99 iterations, i.e. alpha=9.095e+00, with an active set of 91 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:58,418:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=1.408e+01, with an active set of 83 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:58,423:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 105 iterations, alpha=6.530e+00, previous alpha=6.485e+00, with an active set of 96 regressors.
  warnings.warn(

2022-09-26 23:42:58,423:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=1.293e+01, with an active set of 86 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:58,431:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=1.160e+01, with an active set of 90 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:58,445:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 115 iterations, i.e. alpha=6.508e+00, with an active set of 101 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:58,456:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=3.466e+00, with an active set of 108 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:58,460:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=3.167e+00, with an active set of 109 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-09-26 23:42:58,468:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 127 iterations, alpha=3.015e+00, previous alpha=3.013e+00, with an active set of 110 regressors.
  warnings.warn(

2022-09-26 23:42:59,163:INFO:Calculating mean and std
2022-09-26 23:42:59,170:INFO:Creating metrics dataframe
2022-09-26 23:42:59,196:INFO:Uploading results into container
2022-09-26 23:42:59,196:INFO:Uploading model into container now
2022-09-26 23:42:59,201:INFO:master_model_container: 6
2022-09-26 23:42:59,201:INFO:display_container: 2
2022-09-26 23:42:59,201:INFO:LassoLars(random_state=2156)
2022-09-26 23:42:59,201:INFO:create_model() successfully completed......................................
2022-09-26 23:42:59,800:INFO:SubProcess create_model() end ==================================
2022-09-26 23:42:59,805:INFO:Creating metrics dataframe
2022-09-26 23:42:59,871:INFO:Initializing Orthogonal Matching Pursuit
2022-09-26 23:42:59,874:INFO:Total runtime is 0.8450546622276307 minutes
2022-09-26 23:42:59,897:INFO:SubProcess create_model() called ==================================
2022-09-26 23:42:59,897:INFO:Initializing create_model()
2022-09-26 23:42:59,897:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002EDA9D093D0>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:42:59,904:INFO:Checking exceptions
2022-09-26 23:42:59,921:INFO:Importing libraries
2022-09-26 23:42:59,921:INFO:Copying training dataset
2022-09-26 23:42:59,977:INFO:Defining folds
2022-09-26 23:42:59,979:INFO:Declaring metric variables
2022-09-26 23:43:00,019:INFO:Importing untrained model
2022-09-26 23:43:00,043:INFO:Orthogonal Matching Pursuit Imported successfully
2022-09-26 23:43:00,059:INFO:Starting cross validation
2022-09-26 23:43:00,075:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:43:01,571:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:43:01,616:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:43:01,672:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:43:01,672:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:43:01,760:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:43:01,786:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:43:01,832:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:43:01,849:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:43:03,175:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:43:03,175:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-26 23:43:03,573:INFO:Calculating mean and std
2022-09-26 23:43:03,581:INFO:Creating metrics dataframe
2022-09-26 23:43:03,581:INFO:Uploading results into container
2022-09-26 23:43:03,581:INFO:Uploading model into container now
2022-09-26 23:43:03,589:INFO:master_model_container: 7
2022-09-26 23:43:03,589:INFO:display_container: 2
2022-09-26 23:43:03,589:INFO:OrthogonalMatchingPursuit()
2022-09-26 23:43:03,589:INFO:create_model() successfully completed......................................
2022-09-26 23:43:03,991:INFO:SubProcess create_model() end ==================================
2022-09-26 23:43:03,993:INFO:Creating metrics dataframe
2022-09-26 23:43:04,048:INFO:Initializing Bayesian Ridge
2022-09-26 23:43:04,048:INFO:Total runtime is 0.9146199226379396 minutes
2022-09-26 23:43:04,082:INFO:SubProcess create_model() called ==================================
2022-09-26 23:43:04,082:INFO:Initializing create_model()
2022-09-26 23:43:04,082:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002EDA9D093D0>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:43:04,082:INFO:Checking exceptions
2022-09-26 23:43:04,121:INFO:Importing libraries
2022-09-26 23:43:04,123:INFO:Copying training dataset
2022-09-26 23:43:04,203:INFO:Defining folds
2022-09-26 23:43:04,203:INFO:Declaring metric variables
2022-09-26 23:43:04,224:INFO:Importing untrained model
2022-09-26 23:43:04,244:INFO:Bayesian Ridge Imported successfully
2022-09-26 23:43:04,289:INFO:Starting cross validation
2022-09-26 23:43:04,302:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:43:08,088:INFO:Calculating mean and std
2022-09-26 23:43:08,095:INFO:Creating metrics dataframe
2022-09-26 23:43:08,107:INFO:Uploading results into container
2022-09-26 23:43:08,110:INFO:Uploading model into container now
2022-09-26 23:43:08,114:INFO:master_model_container: 8
2022-09-26 23:43:08,114:INFO:display_container: 2
2022-09-26 23:43:08,115:INFO:BayesianRidge()
2022-09-26 23:43:08,115:INFO:create_model() successfully completed......................................
2022-09-26 23:43:08,598:INFO:SubProcess create_model() end ==================================
2022-09-26 23:43:08,599:INFO:Creating metrics dataframe
2022-09-26 23:43:08,677:INFO:Initializing Passive Aggressive Regressor
2022-09-26 23:43:08,680:INFO:Total runtime is 0.9917659799257915 minutes
2022-09-26 23:43:08,704:INFO:SubProcess create_model() called ==================================
2022-09-26 23:43:08,706:INFO:Initializing create_model()
2022-09-26 23:43:08,706:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002EDA9D093D0>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:43:08,706:INFO:Checking exceptions
2022-09-26 23:43:08,732:INFO:Importing libraries
2022-09-26 23:43:08,732:INFO:Copying training dataset
2022-09-26 23:43:08,785:INFO:Defining folds
2022-09-26 23:43:08,785:INFO:Declaring metric variables
2022-09-26 23:43:08,817:INFO:Importing untrained model
2022-09-26 23:43:08,833:INFO:Passive Aggressive Regressor Imported successfully
2022-09-26 23:43:08,865:INFO:Starting cross validation
2022-09-26 23:43:08,883:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:43:14,139:INFO:Calculating mean and std
2022-09-26 23:43:14,147:INFO:Creating metrics dataframe
2022-09-26 23:43:14,171:INFO:Uploading results into container
2022-09-26 23:43:14,175:INFO:Uploading model into container now
2022-09-26 23:43:14,175:INFO:master_model_container: 9
2022-09-26 23:43:14,175:INFO:display_container: 2
2022-09-26 23:43:14,181:INFO:PassiveAggressiveRegressor(random_state=2156)
2022-09-26 23:43:14,182:INFO:create_model() successfully completed......................................
2022-09-26 23:43:14,623:INFO:SubProcess create_model() end ==================================
2022-09-26 23:43:14,623:INFO:Creating metrics dataframe
2022-09-26 23:43:14,691:INFO:Initializing Huber Regressor
2022-09-26 23:43:14,692:INFO:Total runtime is 1.0920282483100892 minutes
2022-09-26 23:43:14,712:INFO:SubProcess create_model() called ==================================
2022-09-26 23:43:14,712:INFO:Initializing create_model()
2022-09-26 23:43:14,712:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002EDA9D093D0>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:43:14,712:INFO:Checking exceptions
2022-09-26 23:43:14,743:INFO:Importing libraries
2022-09-26 23:43:14,744:INFO:Copying training dataset
2022-09-26 23:43:14,785:INFO:Defining folds
2022-09-26 23:43:14,791:INFO:Declaring metric variables
2022-09-26 23:43:14,812:INFO:Importing untrained model
2022-09-26 23:43:14,838:INFO:Huber Regressor Imported successfully
2022-09-26 23:43:14,872:INFO:Starting cross validation
2022-09-26 23:43:14,899:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:43:19,253:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-26 23:43:19,538:INFO:Calculating mean and std
2022-09-26 23:43:19,543:INFO:Creating metrics dataframe
2022-09-26 23:43:19,555:INFO:Uploading results into container
2022-09-26 23:43:19,558:INFO:Uploading model into container now
2022-09-26 23:43:19,558:INFO:master_model_container: 10
2022-09-26 23:43:19,558:INFO:display_container: 2
2022-09-26 23:43:19,562:INFO:HuberRegressor()
2022-09-26 23:43:19,562:INFO:create_model() successfully completed......................................
2022-09-26 23:43:19,844:INFO:SubProcess create_model() end ==================================
2022-09-26 23:43:19,844:INFO:Creating metrics dataframe
2022-09-26 23:43:19,894:INFO:Initializing K Neighbors Regressor
2022-09-26 23:43:19,902:INFO:Total runtime is 1.1788474082946778 minutes
2022-09-26 23:43:19,911:INFO:SubProcess create_model() called ==================================
2022-09-26 23:43:19,911:INFO:Initializing create_model()
2022-09-26 23:43:19,914:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002EDA9D093D0>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:43:19,914:INFO:Checking exceptions
2022-09-26 23:43:19,918:INFO:Importing libraries
2022-09-26 23:43:19,926:INFO:Copying training dataset
2022-09-26 23:43:19,942:INFO:Defining folds
2022-09-26 23:43:19,942:INFO:Declaring metric variables
2022-09-26 23:43:19,950:INFO:Importing untrained model
2022-09-26 23:43:19,969:INFO:K Neighbors Regressor Imported successfully
2022-09-26 23:43:19,985:INFO:Starting cross validation
2022-09-26 23:43:19,999:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:43:23,975:INFO:Calculating mean and std
2022-09-26 23:43:23,986:INFO:Creating metrics dataframe
2022-09-26 23:43:24,005:INFO:Uploading results into container
2022-09-26 23:43:24,005:INFO:Uploading model into container now
2022-09-26 23:43:24,005:INFO:master_model_container: 11
2022-09-26 23:43:24,012:INFO:display_container: 2
2022-09-26 23:43:24,012:INFO:KNeighborsRegressor(n_jobs=-1)
2022-09-26 23:43:24,012:INFO:create_model() successfully completed......................................
2022-09-26 23:43:24,441:INFO:SubProcess create_model() end ==================================
2022-09-26 23:43:24,441:INFO:Creating metrics dataframe
2022-09-26 23:43:24,500:INFO:Initializing Decision Tree Regressor
2022-09-26 23:43:24,507:INFO:Total runtime is 1.2555991570154827 minutes
2022-09-26 23:43:24,523:INFO:SubProcess create_model() called ==================================
2022-09-26 23:43:24,533:INFO:Initializing create_model()
2022-09-26 23:43:24,534:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002EDA9D093D0>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:43:24,534:INFO:Checking exceptions
2022-09-26 23:43:24,560:INFO:Importing libraries
2022-09-26 23:43:24,561:INFO:Copying training dataset
2022-09-26 23:43:24,659:INFO:Defining folds
2022-09-26 23:43:24,659:INFO:Declaring metric variables
2022-09-26 23:43:24,676:INFO:Importing untrained model
2022-09-26 23:43:24,692:INFO:Decision Tree Regressor Imported successfully
2022-09-26 23:43:24,722:INFO:Starting cross validation
2022-09-26 23:43:24,733:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:43:29,323:INFO:Calculating mean and std
2022-09-26 23:43:29,331:INFO:Creating metrics dataframe
2022-09-26 23:43:29,356:INFO:Uploading results into container
2022-09-26 23:43:29,356:INFO:Uploading model into container now
2022-09-26 23:43:29,356:INFO:master_model_container: 12
2022-09-26 23:43:29,364:INFO:display_container: 2
2022-09-26 23:43:29,364:INFO:DecisionTreeRegressor(random_state=2156)
2022-09-26 23:43:29,364:INFO:create_model() successfully completed......................................
2022-09-26 23:43:29,755:INFO:SubProcess create_model() end ==================================
2022-09-26 23:43:29,755:INFO:Creating metrics dataframe
2022-09-26 23:43:29,802:INFO:Initializing Random Forest Regressor
2022-09-26 23:43:29,809:INFO:Total runtime is 1.3439722895622255 minutes
2022-09-26 23:43:29,824:INFO:SubProcess create_model() called ==================================
2022-09-26 23:43:29,827:INFO:Initializing create_model()
2022-09-26 23:43:29,827:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002EDA9D093D0>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:43:29,828:INFO:Checking exceptions
2022-09-26 23:43:29,843:INFO:Importing libraries
2022-09-26 23:43:29,843:INFO:Copying training dataset
2022-09-26 23:43:29,883:INFO:Defining folds
2022-09-26 23:43:29,883:INFO:Declaring metric variables
2022-09-26 23:43:29,903:INFO:Importing untrained model
2022-09-26 23:43:29,928:INFO:Random Forest Regressor Imported successfully
2022-09-26 23:43:29,948:INFO:Starting cross validation
2022-09-26 23:43:29,972:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:43:40,639:INFO:Calculating mean and std
2022-09-26 23:43:40,642:INFO:Creating metrics dataframe
2022-09-26 23:43:40,662:INFO:Uploading results into container
2022-09-26 23:43:40,668:INFO:Uploading model into container now
2022-09-26 23:43:40,672:INFO:master_model_container: 13
2022-09-26 23:43:40,674:INFO:display_container: 2
2022-09-26 23:43:40,676:INFO:RandomForestRegressor(n_jobs=-1, random_state=2156)
2022-09-26 23:43:40,676:INFO:create_model() successfully completed......................................
2022-09-26 23:43:41,187:INFO:SubProcess create_model() end ==================================
2022-09-26 23:43:41,187:INFO:Creating metrics dataframe
2022-09-26 23:43:41,263:INFO:Initializing Extra Trees Regressor
2022-09-26 23:43:41,264:INFO:Total runtime is 1.5348939339319867 minutes
2022-09-26 23:43:41,286:INFO:SubProcess create_model() called ==================================
2022-09-26 23:43:41,289:INFO:Initializing create_model()
2022-09-26 23:43:41,289:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002EDA9D093D0>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:43:41,290:INFO:Checking exceptions
2022-09-26 23:43:41,308:INFO:Importing libraries
2022-09-26 23:43:41,308:INFO:Copying training dataset
2022-09-26 23:43:41,397:INFO:Defining folds
2022-09-26 23:43:41,398:INFO:Declaring metric variables
2022-09-26 23:43:41,417:INFO:Importing untrained model
2022-09-26 23:43:41,435:INFO:Extra Trees Regressor Imported successfully
2022-09-26 23:43:41,462:INFO:Starting cross validation
2022-09-26 23:43:41,479:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:43:50,921:INFO:Calculating mean and std
2022-09-26 23:43:50,932:INFO:Creating metrics dataframe
2022-09-26 23:43:50,936:INFO:Uploading results into container
2022-09-26 23:43:50,944:INFO:Uploading model into container now
2022-09-26 23:43:50,944:INFO:master_model_container: 14
2022-09-26 23:43:50,946:INFO:display_container: 2
2022-09-26 23:43:50,947:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=2156)
2022-09-26 23:43:50,948:INFO:create_model() successfully completed......................................
2022-09-26 23:43:51,193:INFO:SubProcess create_model() end ==================================
2022-09-26 23:43:51,193:INFO:Creating metrics dataframe
2022-09-26 23:43:51,224:INFO:Initializing AdaBoost Regressor
2022-09-26 23:43:51,224:INFO:Total runtime is 1.700891963640849 minutes
2022-09-26 23:43:51,234:INFO:SubProcess create_model() called ==================================
2022-09-26 23:43:51,235:INFO:Initializing create_model()
2022-09-26 23:43:51,235:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002EDA9D093D0>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:43:51,235:INFO:Checking exceptions
2022-09-26 23:43:51,243:INFO:Importing libraries
2022-09-26 23:43:51,243:INFO:Copying training dataset
2022-09-26 23:43:51,262:INFO:Defining folds
2022-09-26 23:43:51,262:INFO:Declaring metric variables
2022-09-26 23:43:51,272:INFO:Importing untrained model
2022-09-26 23:43:51,278:INFO:AdaBoost Regressor Imported successfully
2022-09-26 23:43:51,310:INFO:Starting cross validation
2022-09-26 23:43:51,319:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:43:57,413:INFO:Calculating mean and std
2022-09-26 23:43:57,421:INFO:Creating metrics dataframe
2022-09-26 23:43:57,429:INFO:Uploading results into container
2022-09-26 23:43:57,429:INFO:Uploading model into container now
2022-09-26 23:43:57,429:INFO:master_model_container: 15
2022-09-26 23:43:57,429:INFO:display_container: 2
2022-09-26 23:43:57,434:INFO:AdaBoostRegressor(random_state=2156)
2022-09-26 23:43:57,435:INFO:create_model() successfully completed......................................
2022-09-26 23:43:57,697:INFO:SubProcess create_model() end ==================================
2022-09-26 23:43:57,697:INFO:Creating metrics dataframe
2022-09-26 23:43:57,745:INFO:Initializing Gradient Boosting Regressor
2022-09-26 23:43:57,745:INFO:Total runtime is 1.8095734993616743 minutes
2022-09-26 23:43:57,761:INFO:SubProcess create_model() called ==================================
2022-09-26 23:43:57,761:INFO:Initializing create_model()
2022-09-26 23:43:57,761:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002EDA9D093D0>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:43:57,761:INFO:Checking exceptions
2022-09-26 23:43:57,770:INFO:Importing libraries
2022-09-26 23:43:57,777:INFO:Copying training dataset
2022-09-26 23:43:57,810:INFO:Defining folds
2022-09-26 23:43:57,810:INFO:Declaring metric variables
2022-09-26 23:43:57,822:INFO:Importing untrained model
2022-09-26 23:43:57,836:INFO:Gradient Boosting Regressor Imported successfully
2022-09-26 23:43:57,858:INFO:Starting cross validation
2022-09-26 23:43:57,875:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:44:07,195:INFO:Calculating mean and std
2022-09-26 23:44:07,197:INFO:Creating metrics dataframe
2022-09-26 23:44:07,203:INFO:Uploading results into container
2022-09-26 23:44:07,211:INFO:Uploading model into container now
2022-09-26 23:44:07,211:INFO:master_model_container: 16
2022-09-26 23:44:07,211:INFO:display_container: 2
2022-09-26 23:44:07,211:INFO:GradientBoostingRegressor(random_state=2156)
2022-09-26 23:44:07,211:INFO:create_model() successfully completed......................................
2022-09-26 23:44:07,511:INFO:SubProcess create_model() end ==================================
2022-09-26 23:44:07,511:INFO:Creating metrics dataframe
2022-09-26 23:44:07,568:INFO:Initializing Light Gradient Boosting Machine
2022-09-26 23:44:07,568:INFO:Total runtime is 1.9732915798823043 minutes
2022-09-26 23:44:07,592:INFO:SubProcess create_model() called ==================================
2022-09-26 23:44:07,594:INFO:Initializing create_model()
2022-09-26 23:44:07,594:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002EDA9D093D0>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:44:07,594:INFO:Checking exceptions
2022-09-26 23:44:07,609:INFO:Importing libraries
2022-09-26 23:44:07,609:INFO:Copying training dataset
2022-09-26 23:44:07,642:INFO:Defining folds
2022-09-26 23:44:07,642:INFO:Declaring metric variables
2022-09-26 23:44:07,664:INFO:Importing untrained model
2022-09-26 23:44:07,684:INFO:Light Gradient Boosting Machine Imported successfully
2022-09-26 23:44:07,733:INFO:Starting cross validation
2022-09-26 23:44:07,750:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:44:14,042:INFO:Calculating mean and std
2022-09-26 23:44:14,042:INFO:Creating metrics dataframe
2022-09-26 23:44:14,050:INFO:Uploading results into container
2022-09-26 23:44:14,050:INFO:Uploading model into container now
2022-09-26 23:44:14,058:INFO:master_model_container: 17
2022-09-26 23:44:14,058:INFO:display_container: 2
2022-09-26 23:44:14,058:INFO:LGBMRegressor(random_state=2156)
2022-09-26 23:44:14,058:INFO:create_model() successfully completed......................................
2022-09-26 23:44:14,390:INFO:SubProcess create_model() end ==================================
2022-09-26 23:44:14,392:INFO:Creating metrics dataframe
2022-09-26 23:44:14,455:INFO:Initializing Dummy Regressor
2022-09-26 23:44:14,458:INFO:Total runtime is 2.0880790313084923 minutes
2022-09-26 23:44:14,478:INFO:SubProcess create_model() called ==================================
2022-09-26 23:44:14,478:INFO:Initializing create_model()
2022-09-26 23:44:14,478:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002EDA9D093D0>, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:44:14,478:INFO:Checking exceptions
2022-09-26 23:44:14,501:INFO:Importing libraries
2022-09-26 23:44:14,501:INFO:Copying training dataset
2022-09-26 23:44:14,542:INFO:Defining folds
2022-09-26 23:44:14,542:INFO:Declaring metric variables
2022-09-26 23:44:14,566:INFO:Importing untrained model
2022-09-26 23:44:14,591:INFO:Dummy Regressor Imported successfully
2022-09-26 23:44:14,642:INFO:Starting cross validation
2022-09-26 23:44:14,667:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:44:18,714:INFO:Calculating mean and std
2022-09-26 23:44:18,722:INFO:Creating metrics dataframe
2022-09-26 23:44:18,747:INFO:Uploading results into container
2022-09-26 23:44:18,747:INFO:Uploading model into container now
2022-09-26 23:44:18,756:INFO:master_model_container: 18
2022-09-26 23:44:18,756:INFO:display_container: 2
2022-09-26 23:44:18,756:INFO:DummyRegressor()
2022-09-26 23:44:18,756:INFO:create_model() successfully completed......................................
2022-09-26 23:44:19,219:INFO:SubProcess create_model() end ==================================
2022-09-26 23:44:19,220:INFO:Creating metrics dataframe
2022-09-26 23:44:19,354:INFO:Initializing create_model()
2022-09-26 23:44:19,361:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, estimator=PassiveAggressiveRegressor(random_state=2156), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:44:19,361:INFO:Checking exceptions
2022-09-26 23:44:19,393:INFO:Importing libraries
2022-09-26 23:44:19,393:INFO:Copying training dataset
2022-09-26 23:44:19,435:INFO:Defining folds
2022-09-26 23:44:19,435:INFO:Declaring metric variables
2022-09-26 23:44:19,435:INFO:Importing untrained model
2022-09-26 23:44:19,435:INFO:Declaring custom model
2022-09-26 23:44:19,442:INFO:Passive Aggressive Regressor Imported successfully
2022-09-26 23:44:19,471:INFO:Cross validation set to False
2022-09-26 23:44:19,471:INFO:Fitting Model
2022-09-26 23:44:22,489:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(
2022-09-26 23:44:23,856:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(
2022-09-26 23:44:25,583:INFO:PassiveAggressiveRegressor(random_state=2156)
2022-09-26 23:44:25,583:INFO:create_model() successfully completed......................................
2022-09-26 23:44:26,217:INFO:master_model_container: 18
2022-09-26 23:44:26,219:INFO:display_container: 2
2022-09-26 23:44:26,219:INFO:PassiveAggressiveRegressor(random_state=2156)
2022-09-26 23:44:26,219:INFO:compare_models() successfully completed......................................
2022-09-26 23:51:10,488:INFO:Initializing create_model()
2022-09-26 23:51:10,489:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, estimator=par, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:51:10,490:INFO:Checking exceptions
2022-09-26 23:51:10,608:INFO:Importing libraries
2022-09-26 23:51:10,609:INFO:Copying training dataset
2022-09-26 23:51:10,643:INFO:Defining folds
2022-09-26 23:51:10,644:INFO:Declaring metric variables
2022-09-26 23:51:10,655:INFO:Importing untrained model
2022-09-26 23:51:10,666:INFO:Passive Aggressive Regressor Imported successfully
2022-09-26 23:51:10,678:INFO:Starting cross validation
2022-09-26 23:51:10,686:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:51:26,685:INFO:Calculating mean and std
2022-09-26 23:51:26,688:INFO:Creating metrics dataframe
2022-09-26 23:51:26,697:INFO:Finalizing model
2022-09-26 23:51:28,337:INFO:Uploading results into container
2022-09-26 23:51:28,338:INFO:Uploading model into container now
2022-09-26 23:51:28,359:INFO:master_model_container: 19
2022-09-26 23:51:28,359:INFO:display_container: 3
2022-09-26 23:51:28,360:INFO:PassiveAggressiveRegressor(random_state=2156)
2022-09-26 23:51:28,360:INFO:create_model() successfully completed......................................
2022-09-26 23:53:47,557:INFO:Initializing create_model()
2022-09-26 23:53:47,564:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, estimator=par, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-09-26 23:53:47,565:INFO:Checking exceptions
2022-09-26 23:53:47,653:INFO:Importing libraries
2022-09-26 23:53:47,653:INFO:Copying training dataset
2022-09-26 23:53:47,669:INFO:Defining folds
2022-09-26 23:53:47,670:INFO:Declaring metric variables
2022-09-26 23:53:47,675:INFO:Importing untrained model
2022-09-26 23:53:47,684:INFO:Passive Aggressive Regressor Imported successfully
2022-09-26 23:53:47,697:INFO:Starting cross validation
2022-09-26 23:53:47,717:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-26 23:53:51,531:INFO:Calculating mean and std
2022-09-26 23:53:51,535:INFO:Creating metrics dataframe
2022-09-26 23:53:51,551:INFO:Finalizing model
2022-09-26 23:53:53,541:INFO:Uploading results into container
2022-09-26 23:53:53,541:INFO:Uploading model into container now
2022-09-26 23:53:53,607:INFO:master_model_container: 20
2022-09-26 23:53:53,607:INFO:display_container: 4
2022-09-26 23:53:53,607:INFO:PassiveAggressiveRegressor(random_state=2156)
2022-09-26 23:53:53,607:INFO:create_model() successfully completed......................................
2022-09-26 23:55:19,899:INFO:Initializing plot_model()
2022-09-26 23:55:19,899:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=PassiveAggressiveRegressor(random_state=2156), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, system=True)
2022-09-26 23:55:19,899:INFO:Checking exceptions
2022-09-26 23:55:19,917:INFO:Preloading libraries
2022-09-26 23:55:19,918:INFO:Copying training dataset
2022-09-26 23:55:19,918:INFO:Plot type: residuals
2022-09-26 23:55:23,565:INFO:Fitting Model
2022-09-26 23:55:23,573:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but PassiveAggressiveRegressor was fitted with feature names
  warnings.warn(
2022-09-26 23:55:23,707:INFO:Scoring test/hold-out set
2022-09-26 23:55:25,821:INFO:Visual Rendered Successfully
2022-09-26 23:55:26,197:INFO:plot_model() successfully completed......................................
2022-09-26 23:56:19,894:INFO:Initializing plot_model()
2022-09-26 23:56:19,894:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=PassiveAggressiveRegressor(random_state=2156), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, system=True)
2022-09-26 23:56:19,894:INFO:Checking exceptions
2022-09-26 23:56:19,910:INFO:Preloading libraries
2022-09-26 23:56:19,910:INFO:Copying training dataset
2022-09-26 23:56:19,910:INFO:Plot type: error
2022-09-26 23:56:21,546:INFO:Fitting Model
2022-09-26 23:56:21,546:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but PassiveAggressiveRegressor was fitted with feature names
  warnings.warn(
2022-09-26 23:56:21,546:INFO:Scoring test/hold-out set
2022-09-26 23:56:21,962:INFO:Visual Rendered Successfully
2022-09-26 23:56:22,232:INFO:plot_model() successfully completed......................................
2022-09-26 23:56:56,858:INFO:Initializing plot_model()
2022-09-26 23:56:56,858:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=PassiveAggressiveRegressor(random_state=2156), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, system=True)
2022-09-26 23:56:56,860:INFO:Checking exceptions
2022-09-26 23:56:56,883:INFO:Preloading libraries
2022-09-26 23:56:56,884:INFO:Copying training dataset
2022-09-26 23:56:56,885:INFO:Plot type: feature
2022-09-26 23:56:58,906:INFO:Visual Rendered Successfully
2022-09-26 23:56:59,362:INFO:plot_model() successfully completed......................................
2022-09-26 23:57:23,020:INFO:Initializing evaluate_model()
2022-09-26 23:57:23,020:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, estimator=PassiveAggressiveRegressor(random_state=2156), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2022-09-26 23:57:23,093:INFO:Initializing plot_model()
2022-09-26 23:57:23,093:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=PassiveAggressiveRegressor(random_state=2156), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, system=True)
2022-09-26 23:57:23,093:INFO:Checking exceptions
2022-09-26 23:57:23,100:INFO:Preloading libraries
2022-09-26 23:57:23,100:INFO:Copying training dataset
2022-09-26 23:57:23,100:INFO:Plot type: pipeline
2022-09-26 23:57:23,661:INFO:Visual Rendered Successfully
2022-09-26 23:57:23,926:INFO:plot_model() successfully completed......................................
2022-09-26 23:59:23,636:INFO:Initializing plot_model()
2022-09-26 23:59:23,636:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=PassiveAggressiveRegressor(random_state=2156), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, system=True)
2022-09-26 23:59:23,636:INFO:Checking exceptions
2022-09-26 23:59:23,656:INFO:Preloading libraries
2022-09-26 23:59:23,657:INFO:Copying training dataset
2022-09-26 23:59:23,657:INFO:Plot type: learning
2022-09-26 23:59:26,204:INFO:Fitting Model
2022-09-26 23:59:37,816:INFO:Visual Rendered Successfully
2022-09-26 23:59:38,288:INFO:plot_model() successfully completed......................................
2022-09-26 23:59:56,403:INFO:Initializing evaluate_model()
2022-09-26 23:59:56,403:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, estimator=PassiveAggressiveRegressor(random_state=2156), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2022-09-26 23:59:56,471:INFO:Initializing plot_model()
2022-09-26 23:59:56,471:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=PassiveAggressiveRegressor(random_state=2156), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, system=True)
2022-09-26 23:59:56,471:INFO:Checking exceptions
2022-09-26 23:59:56,482:INFO:Preloading libraries
2022-09-26 23:59:56,483:INFO:Copying training dataset
2022-09-26 23:59:56,483:INFO:Plot type: pipeline
2022-09-26 23:59:56,821:INFO:Visual Rendered Successfully
2022-09-26 23:59:57,093:INFO:plot_model() successfully completed......................................
2022-09-27 00:00:29,263:INFO:Initializing predict_model()
2022-09-27 00:00:29,265:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, estimator=PassiveAggressiveRegressor(random_state=2156), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000002EDACB94CA0>)
2022-09-27 00:00:29,265:INFO:Checking exceptions
2022-09-27 00:00:29,265:INFO:Preloading libraries
2022-09-27 00:00:47,644:INFO:Initializing finalize_model()
2022-09-27 00:00:47,645:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, estimator=PassiveAggressiveRegressor(random_state=2156), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2022-09-27 00:00:47,646:INFO:Finalizing PassiveAggressiveRegressor(random_state=2156)
2022-09-27 00:00:47,659:INFO:Initializing create_model()
2022-09-27 00:00:47,660:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, estimator=PassiveAggressiveRegressor(random_state=2156), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2022-09-27 00:00:47,661:INFO:Checking exceptions
2022-09-27 00:00:47,666:INFO:Importing libraries
2022-09-27 00:00:47,666:INFO:Copying training dataset
2022-09-27 00:00:47,667:INFO:Defining folds
2022-09-27 00:00:47,667:INFO:Declaring metric variables
2022-09-27 00:00:47,667:INFO:Importing untrained model
2022-09-27 00:00:47,667:INFO:Declaring custom model
2022-09-27 00:00:47,669:INFO:Passive Aggressive Regressor Imported successfully
2022-09-27 00:00:47,678:INFO:Cross validation set to False
2022-09-27 00:00:47,679:INFO:Fitting Model
2022-09-27 00:00:49,252:WARNING:c:\Users\HP\AppData\Local\Programs\Python\Python39\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(
2022-09-27 00:00:52,370:INFO:Pipeline(memory=Memory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Id', 'MSSubClass', 'LotFrontage',
                                             'LotArea', 'OverallQual',
                                             'OverallCond', 'YearBuilt',
                                             'YearRemodAdd', 'MasVnrArea',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '1stFlrSF', '2ndFlrSF',
                                             'LowQualFinSF', 'GrLivArea',
                                             'BsmtFullBat...
                                                                         'Foundation',
                                                                         'BsmtFinType1',
                                                                         'BsmtFinType2',
                                                                         'Heating',
                                                                         'GarageType',
                                                                         'SaleCondition'],
                                                                   handle_missing='return_nan',
                                                                   random_state=2156))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 PassiveAggressiveRegressor(random_state=2156))])
2022-09-27 00:00:52,370:INFO:create_model() successfully completed......................................
2022-09-27 00:00:52,570:INFO:Initializing predict_model()
2022-09-27 00:00:52,570:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, estimator=Pipeline(memory=Memory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Id', 'MSSubClass', 'LotFrontage',
                                             'LotArea', 'OverallQual',
                                             'OverallCond', 'YearBuilt',
                                             'YearRemodAdd', 'MasVnrArea',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '1stFlrSF', '2ndFlrSF',
                                             'LowQualFinSF', 'GrLivArea',
                                             'BsmtFullBat...
                                                                         'Foundation',
                                                                         'BsmtFinType1',
                                                                         'BsmtFinType2',
                                                                         'Heating',
                                                                         'GarageType',
                                                                         'SaleCondition'],
                                                                   handle_missing='return_nan',
                                                                   random_state=2156))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 PassiveAggressiveRegressor(random_state=2156))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000002EDACB94940>)
2022-09-27 00:00:52,570:INFO:Checking exceptions
2022-09-27 00:00:52,570:INFO:Preloading libraries
2022-09-27 00:00:52,584:INFO:Set up data.
2022-09-27 00:00:52,601:INFO:Set up index.
2022-09-27 00:00:54,468:INFO:display_container: 6
2022-09-27 00:00:54,468:INFO:master_model_container: 20
2022-09-27 00:00:54,468:INFO:display_container: 6
2022-09-27 00:00:54,509:INFO:Pipeline(memory=Memory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Id', 'MSSubClass', 'LotFrontage',
                                             'LotArea', 'OverallQual',
                                             'OverallCond', 'YearBuilt',
                                             'YearRemodAdd', 'MasVnrArea',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '1stFlrSF', '2ndFlrSF',
                                             'LowQualFinSF', 'GrLivArea',
                                             'BsmtFullBat...
                                                                         'Foundation',
                                                                         'BsmtFinType1',
                                                                         'BsmtFinType2',
                                                                         'Heating',
                                                                         'GarageType',
                                                                         'SaleCondition'],
                                                                   handle_missing='return_nan',
                                                                   random_state=2156))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 PassiveAggressiveRegressor(random_state=2156))])
2022-09-27 00:00:54,510:INFO:finalize_model() successfully completed......................................
2022-09-27 00:02:11,671:INFO:Initializing predict_model()
2022-09-27 00:02:11,671:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, estimator=Pipeline(memory=Memory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Id', 'MSSubClass', 'LotFrontage',
                                             'LotArea', 'OverallQual',
                                             'OverallCond', 'YearBuilt',
                                             'YearRemodAdd', 'MasVnrArea',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '1stFlrSF', '2ndFlrSF',
                                             'LowQualFinSF', 'GrLivArea',
                                             'BsmtFullBat...
                                                                         'Foundation',
                                                                         'BsmtFinType1',
                                                                         'BsmtFinType2',
                                                                         'Heating',
                                                                         'GarageType',
                                                                         'SaleCondition'],
                                                                   handle_missing='return_nan',
                                                                   random_state=2156))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 PassiveAggressiveRegressor(random_state=2156))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000002EDACB94A60>)
2022-09-27 00:02:11,671:INFO:Checking exceptions
2022-09-27 00:02:11,671:INFO:Preloading libraries
2022-09-27 00:02:38,278:INFO:Initializing finalize_model()
2022-09-27 00:02:38,278:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, estimator=PassiveAggressiveRegressor(random_state=2156), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2022-09-27 00:02:38,281:INFO:Finalizing PassiveAggressiveRegressor(random_state=2156)
2022-09-27 00:02:38,292:INFO:Initializing create_model()
2022-09-27 00:02:38,293:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, estimator=PassiveAggressiveRegressor(random_state=2156), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2022-09-27 00:02:38,293:INFO:Checking exceptions
2022-09-27 00:02:38,297:INFO:Importing libraries
2022-09-27 00:02:38,297:INFO:Copying training dataset
2022-09-27 00:02:38,297:INFO:Defining folds
2022-09-27 00:02:38,297:INFO:Declaring metric variables
2022-09-27 00:02:38,298:INFO:Importing untrained model
2022-09-27 00:02:38,298:INFO:Declaring custom model
2022-09-27 00:02:38,299:INFO:Passive Aggressive Regressor Imported successfully
2022-09-27 00:02:38,304:INFO:Cross validation set to False
2022-09-27 00:02:38,304:INFO:Fitting Model
2022-09-27 00:02:39,897:INFO:Pipeline(memory=Memory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Id', 'MSSubClass', 'LotFrontage',
                                             'LotArea', 'OverallQual',
                                             'OverallCond', 'YearBuilt',
                                             'YearRemodAdd', 'MasVnrArea',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '1stFlrSF', '2ndFlrSF',
                                             'LowQualFinSF', 'GrLivArea',
                                             'BsmtFullBat...
                                                                         'Foundation',
                                                                         'BsmtFinType1',
                                                                         'BsmtFinType2',
                                                                         'Heating',
                                                                         'GarageType',
                                                                         'SaleCondition'],
                                                                   handle_missing='return_nan',
                                                                   random_state=2156))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 PassiveAggressiveRegressor(random_state=2156))])
2022-09-27 00:02:39,897:INFO:create_model() successfully completed......................................
2022-09-27 00:02:40,293:INFO:Initializing predict_model()
2022-09-27 00:02:40,297:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002EDADAF2AC0>, estimator=Pipeline(memory=Memory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Id', 'MSSubClass', 'LotFrontage',
                                             'LotArea', 'OverallQual',
                                             'OverallCond', 'YearBuilt',
                                             'YearRemodAdd', 'MasVnrArea',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '1stFlrSF', '2ndFlrSF',
                                             'LowQualFinSF', 'GrLivArea',
                                             'BsmtFullBat...
                                                                         'Foundation',
                                                                         'BsmtFinType1',
                                                                         'BsmtFinType2',
                                                                         'Heating',
                                                                         'GarageType',
                                                                         'SaleCondition'],
                                                                   handle_missing='return_nan',
                                                                   random_state=2156))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 PassiveAggressiveRegressor(random_state=2156))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000002EDADB545E0>)
2022-09-27 00:02:40,297:INFO:Checking exceptions
2022-09-27 00:02:40,297:INFO:Preloading libraries
2022-09-27 00:02:40,299:INFO:Set up data.
2022-09-27 00:02:40,331:INFO:Set up index.
2022-09-27 00:02:41,866:INFO:display_container: 7
2022-09-27 00:02:41,866:INFO:master_model_container: 20
2022-09-27 00:02:41,866:INFO:display_container: 7
2022-09-27 00:02:41,913:INFO:Pipeline(memory=Memory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Id', 'MSSubClass', 'LotFrontage',
                                             'LotArea', 'OverallQual',
                                             'OverallCond', 'YearBuilt',
                                             'YearRemodAdd', 'MasVnrArea',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '1stFlrSF', '2ndFlrSF',
                                             'LowQualFinSF', 'GrLivArea',
                                             'BsmtFullBat...
                                                                         'Foundation',
                                                                         'BsmtFinType1',
                                                                         'BsmtFinType2',
                                                                         'Heating',
                                                                         'GarageType',
                                                                         'SaleCondition'],
                                                                   handle_missing='return_nan',
                                                                   random_state=2156))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 PassiveAggressiveRegressor(random_state=2156))])
2022-09-27 00:02:41,913:INFO:finalize_model() successfully completed......................................
